I1129 14:14:42.360612   95247 main.go:675] Cluster Autoscaler 1.31.1
W1129 14:14:42.361020   95247 main.go:680] Error reading gardener autoscaler version, err: read VERSION: is a directory
I1129 14:14:42.361175   95247 client.go:48] Using kubeconfig file: /Users/i544000/go/src/k8s.io/autoscaler/cluster-autoscaler/dev/kubeconfigs/kubeconfig_target.yaml
I1129 14:14:42.363661   95247 framework.go:392] "the scheduler starts to work with those plugins" Plugins={"PreEnqueue":{"Enabled":[{"Name":"SchedulingGates","Weight":0}],"Disabled":null},"QueueSort":{"Enabled":[{"Name":"PrioritySort","Weight":0}],"Disabled":null},"PreFilter":{"Enabled":[{"Name":"NodeAffinity","Weight":0},{"Name":"NodePorts","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeRestrictions","Weight":0},{"Name":"NodeVolumeLimits","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"VolumeZone","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0}],"Disabled":null},"Filter":{"Enabled":[{"Name":"NodeUnschedulable","Weight":0},{"Name":"NodeName","Weight":0},{"Name":"TaintToleration","Weight":0},{"Name":"NodeAffinity","Weight":0},{"Name":"NodePorts","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeRestrictions","Weight":0},{"Name":"NodeVolumeLimits","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"VolumeZone","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0}],"Disabled":null},"PostFilter":{"Enabled":[{"Name":"DefaultPreemption","Weight":0}],"Disabled":null},"PreScore":{"Enabled":[{"Name":"TaintToleration","Weight":0},{"Name":"NodeAffinity","Weight":0},{"Name":"NodeResourcesFit","Weight":0},{"Name":"VolumeBinding","Weight":0},{"Name":"PodTopologySpread","Weight":0},{"Name":"InterPodAffinity","Weight":0},{"Name":"NodeResourcesBalancedAllocation","Weight":0}],"Disabled":null},"Score":{"Enabled":[{"Name":"TaintToleration","Weight":3},{"Name":"NodeAffinity","Weight":2},{"Name":"NodeResourcesFit","Weight":1},{"Name":"VolumeBinding","Weight":1},{"Name":"PodTopologySpread","Weight":2},{"Name":"InterPodAffinity","Weight":2},{"Name":"NodeResourcesBalancedAllocation","Weight":1},{"Name":"ImageLocality","Weight":1}],"Disabled":null},"Reserve":{"Enabled":[{"Name":"VolumeBinding","Weight":0}],"Disabled":null},"Permit":{"Enabled":null,"Disabled":null},"PreBind":{"Enabled":[{"Name":"VolumeBinding","Weight":0}],"Disabled":null},"Bind":{"Enabled":[{"Name":"DefaultBinder","Weight":0}],"Disabled":null},"PostBind":{"Enabled":null,"Disabled":null},"MultiPoint":{"Enabled":null,"Disabled":null}}
I1129 14:14:43.339344   95247 cloud_provider_builder.go:30] Building mcm cloud provider.
W1129 14:14:43.339454   95247 client_config.go:659] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
W1129 14:14:43.339464   95247 client_config.go:664] error creating inClusterConfig, falling back to default config: unable to load in-cluster configuration, KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT must be defined
I1129 14:14:45.223487   95247 reflector.go:305] Starting reflector *v1.Node (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.223594   95247 reflector.go:341] Listing and watching *v1.Node from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.223774   95247 reflector.go:305] Starting reflector *v1alpha1.MachineClass (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.223800   95247 reflector.go:341] Listing and watching *v1alpha1.MachineClass from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.223946   95247 reflector.go:305] Starting reflector *v1alpha1.MachineSet (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.223959   95247 reflector.go:341] Listing and watching *v1alpha1.MachineSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224002   95247 reflector.go:305] Starting reflector *v1alpha1.Machine (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224147   95247 reflector.go:341] Listing and watching *v1alpha1.Machine from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224596   95247 reflector.go:305] Starting reflector *v1alpha1.MachineDeployment (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224625   95247 reflector.go:341] Listing and watching *v1alpha1.MachineDeployment from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224696   95247 reflector.go:305] Starting reflector *v1.Deployment (1h0m0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.224713   95247 reflector.go:341] Listing and watching *v1.Deployment from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.481137   95247 reflector.go:368] Caches populated for *v1alpha1.MachineClass from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.481602   95247 reflector.go:368] Caches populated for *v1alpha1.Machine from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.481651   95247 reflector.go:368] Caches populated for *v1alpha1.MachineSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.482257   95247 reflector.go:368] Caches populated for *v1alpha1.MachineDeployment from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.883277   95247 reflector.go:368] Caches populated for *v1.Node from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924165   95247 taints.go:105] Startup taint node.gardener.cloud/critical-components-not-ready on all NodeGroups
I1129 14:14:45.924188   95247 taints.go:105] Startup taint testing.node.gardener.cloud/initial-node-blocked on all NodeGroups
I1129 14:14:45.924423   95247 reflector.go:305] Starting reflector *v1.PersistentVolumeClaim (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924436   95247 reflector.go:341] Listing and watching *v1.PersistentVolumeClaim from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924456   95247 reflector.go:305] Starting reflector *v1.Pod (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924464   95247 reflector.go:341] Listing and watching *v1.Pod from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924476   95247 reflector.go:305] Starting reflector *v1.PodDisruptionBudget (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924486   95247 reflector.go:341] Listing and watching *v1.PodDisruptionBudget from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924574   95247 reflector.go:305] Starting reflector *v1.StorageClass (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924583   95247 reflector.go:341] Listing and watching *v1.StorageClass from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924703   95247 reflector.go:305] Starting reflector *v1.DaemonSet (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924710   95247 reflector.go:341] Listing and watching *v1.DaemonSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924785   95247 reflector.go:305] Starting reflector *v1.StatefulSet (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924791   95247 reflector.go:341] Listing and watching *v1.StatefulSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924845   95247 reflector.go:305] Starting reflector *v1.ReplicationController (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924851   95247 reflector.go:341] Listing and watching *v1.ReplicationController from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924897   95247 reflector.go:305] Starting reflector *v1.PersistentVolume (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924900   95247 reflector.go:305] Starting reflector *v1.CSIDriver (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924903   95247 reflector.go:341] Listing and watching *v1.PersistentVolume from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924906   95247 reflector.go:341] Listing and watching *v1.CSIDriver from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924986   95247 reflector.go:305] Starting reflector *v1.CSINode (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924991   95247 reflector.go:341] Listing and watching *v1.CSINode from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925042   95247 reflector.go:305] Starting reflector *v1.Service (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925048   95247 reflector.go:341] Listing and watching *v1.Service from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925062   95247 reflector.go:305] Starting reflector *v1.ReplicaSet (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925067   95247 reflector.go:341] Listing and watching *v1.ReplicaSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925073   95247 reflector.go:305] Starting reflector *v1.CSIStorageCapacity (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925080   95247 reflector.go:341] Listing and watching *v1.CSIStorageCapacity from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924420   95247 reflector.go:305] Starting reflector *v1.Namespace (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925113   95247 reflector.go:341] Listing and watching *v1.Namespace from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.924426   95247 reflector.go:305] Starting reflector *v1.Node (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925175   95247 reflector.go:341] Listing and watching *v1.Node from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925161   95247 reflector.go:305] Starting reflector *v1.Job (0s) from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925219   95247 reflector.go:341] Listing and watching *v1.Job from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:45.925350   95247 main.go:456] Registered cleanup signal handler
I1129 14:14:45.925424   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:14:45.925541   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 110.292Âµs
I1129 14:14:46.125242   95247 request.go:632] Waited for 200.067209ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/api/v1/services?limit=500&resourceVersion=0
I1129 14:14:46.145606   95247 reflector.go:368] Caches populated for *v1.CSINode from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.145649   95247 reflector.go:368] Caches populated for *v1.StorageClass from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.145666   95247 reflector.go:368] Caches populated for *v1.StatefulSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.145740   95247 reflector.go:368] Caches populated for *v1.PodDisruptionBudget from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.145824   95247 reflector.go:368] Caches populated for *v1.PersistentVolume from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.145919   95247 reflector.go:368] Caches populated for *v1.CSIDriver from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.146004   95247 reflector.go:368] Caches populated for *v1.PersistentVolumeClaim from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.146050   95247 reflector.go:368] Caches populated for *v1.ReplicationController from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.325298   95247 request.go:632] Waited for 400.046042ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0
I1129 14:14:46.368658   95247 reflector.go:368] Caches populated for *v1.DaemonSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.525641   95247 request.go:632] Waited for 600.432541ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces?limit=500&resourceVersion=0
I1129 14:14:46.581724   95247 reflector.go:368] Caches populated for *v1.Service from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.582143   95247 reflector.go:368] Caches populated for *v1.CSIStorageCapacity from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.584692   95247 reflector.go:368] Caches populated for *v1.Pod from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.724703   95247 request.go:632] Waited for 799.41975ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/api/v1/nodes?limit=500&resourceVersion=0
I1129 14:14:46.745808   95247 reflector.go:368] Caches populated for *v1.Namespace from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:46.924988   95247 request.go:632] Waited for 999.645875ms due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/apis/apps/v1/replicasets?limit=500&resourceVersion=0
I1129 14:14:46.946051   95247 reflector.go:368] Caches populated for *v1.Node from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:47.125628   95247 request.go:632] Waited for 1.200289083s due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/apis/batch/v1/jobs?limit=500&resourceVersion=0
I1129 14:14:47.125645   95247 request.go:700] Waited for 1.200289083s due to client-side throttling, not priority and fairness, request: GET:https://api.ca-it.i544000.shoot.dev.k8s-hana.ondemand.com/apis/batch/v1/jobs?limit=500&resourceVersion=0
I1129 14:14:47.144904   95247 reflector.go:368] Caches populated for *v1.ReplicaSet from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:47.311378   95247 reflector.go:368] Caches populated for *v1.Deployment from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:47.345487   95247 reflector.go:368] Caches populated for *v1.Job from pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243
I1129 14:14:55.926744   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:14:55.927048   95247 static_autoscaler.go:306] Starting main loop
I1129 14:14:55.927320   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:14:55.927422   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:14:55.928346   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:14:55.929488   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:14:55.929508   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:14:55.929534   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:14:55.930081   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:14:55.930096   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:14:55.930110   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:14:55.930565   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:14:55.930581   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:14:55.930594   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:14:55.931328   95247 clusterstate.go:480] AcceptableRanges have not been populated yet. Skip checking
W1129 14:14:55.931338   95247 clusterstate.go:480] AcceptableRanges have not been populated yet. Skip checking
W1129 14:14:55.931343   95247 clusterstate.go:480] AcceptableRanges have not been populated yet. Skip checking
W1129 14:14:55.931347   95247 clusterstate.go:480] AcceptableRanges have not been populated yet. Skip checking
I1129 14:14:55.931389   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:14:55.931851   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:14:55.932265   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-76769870114981126-upcoming-0
I1129 14:14:55.932395   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:14:55.932508   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:14:55.932521   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:14:55.932529   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:14:55.932556   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:14:55.932581   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:14:55.932627   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:14:55.932952   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:14:55.933205   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:06.378467   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:06.378742   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:06.378827   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:06.379901   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:06.380878   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:06.380904   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:06.380929   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:06.381605   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:06.381627   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:06.381665   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:06.382250   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:06.382270   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:06.382288   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:06.382974   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:06.383490   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:06.383721   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5859905995666368932-upcoming-0
I1129 14:15:06.383785   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:06.383812   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:06.383827   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:06.383837   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:06.383872   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:06.383903   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:06.383945   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:06.383962   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:06.384040   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:16.974706   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:16.974920   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:16.974971   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:16.975506   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:16.976253   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:16.976277   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:16.976306   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:16.976877   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:16.976906   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:16.976932   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:16.977483   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:16.977501   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:16.977518   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:16.978105   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:16.978546   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:16.978722   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-8889022527009516159-upcoming-0
I1129 14:15:16.978741   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:16.978750   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:16.978755   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:16.978759   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:16.978773   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:16.978792   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:16.978823   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:16.978831   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:16.978863   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:27.424066   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:27.424127   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:27.424136   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:27.424290   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:27.424298   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:27.424306   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:27.424461   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:27.424467   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:27.424475   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:27.424596   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:27.424604   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:27.424608   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:27.424744   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:27.424969   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:27.425079   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:27.425126   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-402677333125182619-upcoming-0
I1129 14:15:27.425136   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:27.425140   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:27.425142   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:27.425144   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:27.425151   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:27.425156   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:27.425162   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:27.425166   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:27.425180   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:37.872362   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:37.872437   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:37.872481   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:37.872849   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:37.872866   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:37.872886   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:37.873285   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:37.873294   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:37.873303   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:37.873597   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:37.873610   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:37.873618   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:37.873887   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:37.874180   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:37.874395   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:37.874486   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-296965005298931670-upcoming-0
I1129 14:15:37.874509   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:37.874520   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:37.874526   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:37.874530   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:37.874545   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:37.874561   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:37.874581   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:37.874591   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:37.874624   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:48.328213   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:48.328534   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:48.328613   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:48.329251   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:48.329269   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:48.329301   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:48.330073   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:48.330090   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:48.330111   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:48.330532   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:48.330547   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:48.330557   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:48.330901   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:48.331483   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:48.331910   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:48.332103   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-4135746965439770731-upcoming-0
I1129 14:15:48.332129   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:48.332143   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:48.332151   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:48.332157   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:48.332184   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:48.332201   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:48.332225   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:48.332237   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:48.332288   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:15:58.780529   95247 static_autoscaler.go:306] Starting main loop
I1129 14:15:58.780789   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:58.780872   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:15:58.781706   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:15:58.782641   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:58.782667   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:58.782692   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:58.783650   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:58.783674   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:58.783693   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:58.784329   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:15:58.784349   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:15:58.784368   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:15:58.785326   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:58.786137   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:15:58.786539   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5992587705341964545-upcoming-0
I1129 14:15:58.786581   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:15:58.786687   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:15:58.786703   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:15:58.786713   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:15:58.786755   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:15:58.786790   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:15:58.786852   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:15:58.786868   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:15:58.786936   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:16:09.320165   95247 static_autoscaler.go:306] Starting main loop
I1129 14:16:09.320373   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:09.320428   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:09.321194   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:16:09.321778   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:09.321793   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:09.321816   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:09.322260   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:09.322271   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:09.322282   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:09.322729   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:09.322739   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:09.322750   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:09.323199   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:09.323565   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:16:09.323754   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-595368165704166776-upcoming-0
I1129 14:16:09.323809   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:16:09.323826   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:16:09.323835   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:16:09.323840   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:16:09.323857   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:16:09.323873   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:16:09.323900   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:09.323910   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:16:09.323962   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:16:19.767473   95247 static_autoscaler.go:306] Starting main loop
I1129 14:16:19.767766   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:19.767835   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:19.768799   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:16:19.770089   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:19.770132   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:19.770162   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:19.770809   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:19.770832   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:19.770858   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:19.771446   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:19.771467   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:19.771486   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:19.772115   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:19.772590   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:16:19.772838   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-414320504545247645-upcoming-0
I1129 14:16:19.772882   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:16:19.772906   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:16:19.772920   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:16:19.772930   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:16:19.772964   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:16:19.772995   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:16:19.773031   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:19.773052   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:16:19.773131   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:16:30.312177   95247 static_autoscaler.go:306] Starting main loop
I1129 14:16:30.312441   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:30.312496   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:30.313346   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:16:30.314281   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:30.314330   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:30.314370   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:30.315108   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:30.315129   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:30.315148   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:30.315736   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:30.315756   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:30.315775   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:30.316443   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:30.316988   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:16:30.317240   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-7074185438553089813-upcoming-0
I1129 14:16:30.317295   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:16:30.317318   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:16:30.317332   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:16:30.317342   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:16:30.317377   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:16:30.317409   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:16:30.317476   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:30.317499   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:16:30.317581   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:16:40.767076   95247 static_autoscaler.go:306] Starting main loop
I1129 14:16:40.767348   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:40.767407   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:40.768246   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:40.768282   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:40.768323   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:40.769270   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:40.769292   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:40.769313   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:40.770107   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:40.770128   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:40.770156   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:40.770730   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:16:40.771427   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:40.771935   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:16:40.772175   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-7270443757769656617-upcoming-0
I1129 14:16:40.772215   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:16:40.772240   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:16:40.772253   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:16:40.772264   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:16:40.772298   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:16:40.772330   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:16:40.772369   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:40.772386   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:16:40.772566   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:16:45.926402   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:16:45.926632   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 167.542Âµs
I1129 14:16:51.218986   95247 static_autoscaler.go:306] Starting main loop
I1129 14:16:51.219233   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:51.219296   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:16:51.220083   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:51.220113   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:51.220159   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:51.221107   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:16:51.221883   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:51.221905   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:51.221926   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:51.222527   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:16:51.222549   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:16:51.222569   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:16:51.223378   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:51.223958   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:16:51.224228   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-7770318846858592629-upcoming-0
I1129 14:16:51.224279   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:16:51.224302   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:16:51.224315   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:16:51.224325   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:16:51.224361   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:16:51.224392   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:16:51.224437   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:16:51.224460   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:16:51.224543   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:17:01.750253   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:01.750441   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:01.750518   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:01.751097   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:01.751115   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:01.751144   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:01.751663   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:01.751959   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:01.751968   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:01.751977   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:01.752311   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:01.752322   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:01.752330   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:01.752642   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:01.752951   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:01.753156   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-1894477238952641310-upcoming-0
I1129 14:17:01.753192   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:17:01.753204   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:17:01.753212   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:01.753217   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:17:01.753233   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:17:01.753245   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:17:01.753269   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:01.753278   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:17:01.753327   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:17:12.245697   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:12.245978   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:12.246064   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:12.246887   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:12.247750   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:12.247784   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:12.247846   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:12.248534   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:12.248559   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:12.248579   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:12.249116   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:12.249136   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:12.249154   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:12.249742   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:12.250259   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:12.250499   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-1215681368019641194-upcoming-0
I1129 14:17:12.250533   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:17:12.250555   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:17:12.250568   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:12.250578   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:17:12.250613   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:17:12.250648   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:17:12.250695   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:12.250712   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:17:12.250792   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:17:22.742621   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:22.742947   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:22.743019   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:22.743836   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:22.744649   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:22.744676   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:22.744703   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:22.745256   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:22.745276   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:22.745298   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:22.745870   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:22.745892   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:22.745910   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:22.746505   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:22.746984   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:22.747228   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-6428628709042584437-upcoming-0
I1129 14:17:22.747265   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:17:22.747288   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:17:22.747303   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:22.747313   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:17:22.747349   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:17:22.747380   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:17:22.747425   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:22.747442   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:17:22.747522   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:17:33.194188   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:33.194424   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:33.194516   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:33.195311   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:33.196047   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:33.196076   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:33.196101   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:33.198346   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:33.198373   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:33.198394   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:33.198987   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:33.199007   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:33.199050   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:33.199872   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:33.200005   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:33.200252   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-tf2mh: cannot put pod scale-up-pod-6775c8dc87-tf2mh on any node
I1129 14:17:33.200320   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:17:33.200345   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:17:33.200358   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:33.200371   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:17:33.200399   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh is unschedulable
I1129 14:17:33.200793   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:17:33.201186   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-tf2mh can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:17:33.201751   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:17:33.202071   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-2901453492358764939 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3319308975599611294 are not similar, ephemeral-storage does not match
I1129 14:17:33.202665   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-7591895965187329556 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3319308975599611294 are not similar, ephemeral-storage does not match
I1129 14:17:33.203124   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-551232259726094507 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3319308975599611294 are not similar, ephemeral-storage does not match
I1129 14:17:33.203680   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:17:33.203732   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:17:33.203743   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z3 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:17:33.203763   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z3
I1129 14:17:33.203791   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-three-zones-z3
I1129 14:17:33.203832   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-551232259726094507 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3319308975599611294 are not similar, ephemeral-storage does not match
I1129 14:17:33.203919   95247 orchestrator.go:697] Found 2 similar node groups: [shoot--i544000--ca-it-three-zones-z1 shoot--i544000--ca-it-three-zones-z2]
I1129 14:17:33.203946   95247 orchestrator.go:713] Splitting scale-up between 3 similar node groups: {shoot--i544000--ca-it-three-zones-z3, shoot--i544000--ca-it-three-zones-z1, shoot--i544000--ca-it-three-zones-z2}
I1129 14:17:33.203980   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)}]
I1129 14:17:33.204048   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z3 size to 1
I1129 14:17:33.204180   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z3 by 1
I1129 14:17:33.204315   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"8776", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z3 size to 1 instead of 0 (max: 1)
I1129 14:17:33.951587   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"8776", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z3 size set to 1 instead of 0 (max: 1)
I1129 14:17:33.951696   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W1129 14:17:33.951795   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z3
I1129 14:17:34.173931   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-tf2mh", UID:"e7b9b60d-dd28-464a-b715-7af5c0dbc7c1", APIVersion:"v1", ResourceVersion:"7515", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)}]
I1129 14:17:44.401104   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:44.401332   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:44.401392   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:44.401958   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:44.401978   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:44.402007   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:44.402660   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:44.402982   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:44.402997   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:44.403008   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:44.403331   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:44.403357   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:44.403367   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:17:44.403637   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z3
I1129 14:17:44.403696   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:44.404088   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:44.404289   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-6938103839139647032-upcoming-0
I1129 14:17:44.404306   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:17:44.404320   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:17:44.404329   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:44.404334   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:17:44.404353   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:17:44.404380   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:17:44.404405   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:44.404416   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:17:44.404429   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:17:44.404483   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:17:54.844791   95247 static_autoscaler.go:306] Starting main loop
I1129 14:17:54.844944   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:54.845029   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:17:54.845658   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:54.845680   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:54.845714   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:54.846766   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:54.846784   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:54.846801   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:54.847464   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:17:54.848201   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:17:54.848219   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:17:54.848270   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:17:54.849117   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:54.849242   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:17:54.849838   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:17:54.850085   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-7291541039429984166-upcoming-0
I1129 14:17:54.850126   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:17:54.850149   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:17:54.850163   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:17:54.850172   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:17:54.850205   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:17:54.850236   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:17:54.850280   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:17:54.850297   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:17:54.850323   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:17:54.850403   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:05.327966   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:05.328256   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:05.328319   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:05.329100   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:05.329125   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:05.329174   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:05.329986   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:05.330511   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:05.330534   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:05.330553   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:05.331091   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:05.331112   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:05.331133   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:05.331869   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:05.331981   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:18:05.332451   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:05.332700   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-9098334054090069284-upcoming-0
I1129 14:18:05.332743   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:05.332767   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:05.332780   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:05.332789   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:05.332823   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:05.332861   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:05.332903   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:05.332924   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:05.332949   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:18:05.333028   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:15.781356   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:15.781642   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:15.781715   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:15.782545   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:15.782574   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:15.782620   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:15.783442   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:15.783464   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:15.783486   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:15.784154   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:15.784175   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:15.784194   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:15.784768   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:15.785507   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:15.785619   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:18:15.786224   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:15.786485   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-347730932774369724-upcoming-0
I1129 14:18:15.786536   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:15.786558   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:15.786572   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:15.786581   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:15.786614   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:15.786646   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:15.786694   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:15.786710   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:15.786735   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:18:15.786818   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:26.233615   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:26.233909   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:26.233976   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:26.234719   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:26.234750   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:26.234788   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:26.235664   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:26.235684   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:26.235709   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:26.236591   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:26.236613   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:26.236646   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:26.237307   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:26.238202   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:26.238328   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:18:26.238837   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:26.239125   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-1109211169892988869-upcoming-0
I1129 14:18:26.239203   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:26.239242   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:26.239256   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:26.239266   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:26.239300   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:26.239335   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:26.239378   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:26.239396   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:26.239423   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:18:26.239504   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:36.757572   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:36.757992   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:36.758091   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:36.758934   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:36.758965   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:36.759042   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:36.760099   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:36.760122   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:36.760145   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:36.761483   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:36.761521   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:36.761545   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:36.762307   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:36.763017   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
W1129 14:18:36.763054   95247 mcm_cloud_provider.go:155] Node ip-10-180-13-238.eu-west-1.compute.internal has no providerId
I1129 14:18:36.763575   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:36.763835   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-2765055820618565922-upcoming-0
I1129 14:18:36.763870   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:36.763892   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:36.763906   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:36.763915   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:36.763950   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:36.763984   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:36.764029   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:36.764050   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:36.764076   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
W1129 14:18:36.764086   95247 mcm_cloud_provider.go:155] Node ip-10-180-13-238.eu-west-1.compute.internal has no providerId
I1129 14:18:36.764095   95247 pre_filtering_processor.go:57] Node ip-10-180-13-238.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:36.764175   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:45.906702   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:18:45.907023   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 253.042Âµs
I1129 14:18:47.501988   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:47.503747   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:47.504059   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:47.505237   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:47.506968   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:47.506992   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-13-238.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:47.507031   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:47.508481   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:47.508502   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:47.508537   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:47.510128   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:47.510151   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:47.510185   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:47.511365   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:47.512205   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:47.512416   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-7086859820442642863-upcoming-0
I1129 14:18:47.512435   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:47.512458   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:47.512468   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:47.512476   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:47.512502   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:47.512524   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:47.512552   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:47.512564   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:47.512592   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:18:47.512657   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:18:57.958419   95247 static_autoscaler.go:306] Starting main loop
I1129 14:18:57.958718   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:57.958785   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:18:57.959883   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:18:57.960880   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:57.960904   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:57.960930   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:57.961734   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:57.961757   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-13-238.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:57.961779   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:57.962402   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:18:57.962427   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:18:57.962448   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:18:57.963165   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:57.963741   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:18:57.963975   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-7441278471066067240-upcoming-0
I1129 14:18:57.964012   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:18:57.964034   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:18:57.964048   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:18:57.964057   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:18:57.964091   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:18:57.964126   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:18:57.964172   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:18:57.964202   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:18:57.964226   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:18:57.964306   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:17:33.19411 +0530 IST m=+170.864228168 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:19:08.452616   95247 static_autoscaler.go:306] Starting main loop
I1129 14:19:08.452802   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:08.452851   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:08.452884   95247 taints.go:442] Overriding status of node ip-10-180-13-238.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:19:08.453545   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:19:08.454120   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:08.454140   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:08.454154   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:08.454537   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:08.454547   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:08.454560   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:08.454850   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:08.454859   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:08.454868   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:08.455262   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:08.455584   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:19:08.455768   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tf2mh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-1820183914820842839-upcoming-0
I1129 14:19:08.455860   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-6v2lc: cannot put pod scale-up-pod-6775c8dc87-6v2lc on any node
I1129 14:19:08.455985   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-4x7jt based on similar pods scheduling
I1129 14:19:08.455998   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:19:08.456010   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:19:08.456017   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:19:08.456022   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 2 unschedulable pods left
I1129 14:19:08.456035   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc is unschedulable
I1129 14:19:08.456039   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt is unschedulable
I1129 14:19:08.456101   95247 orchestrator.go:111] Upcoming 1 nodes
I1129 14:19:08.456184   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:19:08.456327   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-6v2lc can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:19:08.456337   95247 orchestrator.go:597] 1 other pods similar to scale-up-pod-6775c8dc87-6v2lc can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:19:08.456571   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:19:08.456603   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-2614992010982266490 and template-node-for-shoot--i544000--ca-it-one-zone-z1-1371295869288203870 are not similar, ephemeral-storage does not match
I1129 14:19:08.457322   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-7085240752797879491 and template-node-for-shoot--i544000--ca-it-one-zone-z1-1371295869288203870 are not similar, ephemeral-storage does not match
I1129 14:19:08.457932   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:19:08.457954   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:19:08.457967   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z1
I1129 14:19:08.457976   95247 orchestrator.go:190] Estimated 2 nodes needed in shoot--i544000--ca-it-three-zones-z1
I1129 14:19:08.458019   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-2614992010982266490 and template-node-for-shoot--i544000--ca-it-one-zone-z1-1371295869288203870 are not similar, ephemeral-storage does not match
I1129 14:19:08.458050   95247 orchestrator.go:697] Found 1 similar node groups: [shoot--i544000--ca-it-three-zones-z2]
I1129 14:19:08.458065   95247 orchestrator.go:713] Splitting scale-up between 2 similar node groups: {shoot--i544000--ca-it-three-zones-z1, shoot--i544000--ca-it-three-zones-z2}
I1129 14:19:08.458087   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:19:08.458107   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1
I1129 14:19:08.458135   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z2 by 1
I1129 14:19:08.458191   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"9548", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1 instead of 0 (max: 1)
I1129 14:19:09.122509   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z1 size to 2
I1129 14:19:09.122564   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z1 by 1
I1129 14:19:09.122590   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"9548", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z2 size set to 1 instead of 0 (max: 1)
I1129 14:19:09.347094   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"9548", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z1 size to 2 instead of 1 (max: 2)
I1129 14:19:09.713551   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I1129 14:19:09.713578   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"9548", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z1 size set to 2 instead of 1 (max: 2)
I1129 14:19:09.936534   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-6v2lc", UID:"9c3bad69-de92-4940-bb18-eef9128914e8", APIVersion:"v1", ResourceVersion:"9606", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:19:10.371583   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-4x7jt", UID:"4ce108ca-89cb-4acb-b899-bae8545b9bcd", APIVersion:"v1", ResourceVersion:"9603", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:19:20.372682   95247 static_autoscaler.go:306] Starting main loop
I1129 14:19:20.372861   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:20.372933   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:20.373908   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:20.373934   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:20.373974   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:20.374803   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:19:20.375361   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:20.375382   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:20.375402   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:20.375949   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:20.375968   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:20.375990   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:20.376953   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:20.377073   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z3 finished successfully in 1m46.442224167s
I1129 14:19:20.377147   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:19:20.377987   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:19:20.378262   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-8337344890201833214-upcoming-0
I1129 14:19:20.378418   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-1036025383295855433-upcoming-0
I1129 14:19:20.378446   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:19:20.378468   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:19:20.378483   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:19:20.378492   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:19:20.378526   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:19:20.378561   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:19:20.378605   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:20.378624   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:19:20.378875   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:19:20.378900   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:19:20.379000   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:19:20.379039   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:19:20.379096   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:19:20.379186   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 0s
I1129 14:19:20.379274   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:19:20.379327   95247 static_autoscaler.go:647] Starting scale down
I1129 14:19:20.379382   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 0s
I1129 14:19:20.379596   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:20.678770   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:19:31.129925   95247 static_autoscaler.go:306] Starting main loop
I1129 14:19:31.130114   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:31.130155   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:31.130813   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:31.130827   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:31.130853   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:31.131409   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:19:31.131678   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:31.131689   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:31.131700   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:31.131966   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:31.131975   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:31.131985   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:31.132384   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:31.132491   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:19:31.132947   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:19:31.133084   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-4749231914033478765-upcoming-0
I1129 14:19:31.133184   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-5849086324674078979-upcoming-0
I1129 14:19:31.133208   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:19:31.133219   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:19:31.133226   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:19:31.133230   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:19:31.133253   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:19:31.133265   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:19:31.133287   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:31.133296   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:19:31.133464   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:19:31.133478   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:19:31.133535   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:19:31.133570   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:19:31.133607   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:19:31.133633   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 10.757418458s
I1129 14:19:31.133678   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:19:31.133701   95247 static_autoscaler.go:647] Starting scale down
I1129 14:19:31.133727   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 10.757418458s
I1129 14:19:31.133773   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:41.593909   95247 static_autoscaler.go:306] Starting main loop
I1129 14:19:41.594208   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:41.594271   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:41.595281   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:41.595315   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-13-238.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:41.595364   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:41.596260   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:41.596290   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-13-238.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:41.596312   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:41.596858   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:19:41.597397   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:41.597417   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:41.597438   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:41.598235   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:41.598390   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:19:41.599181   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:19:41.599385   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-3971239580399815022-upcoming-0
I1129 14:19:41.599472   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-9054673662366884863-upcoming-0
I1129 14:19:41.599495   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:19:41.599514   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:19:41.599529   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:19:41.599537   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:19:41.599570   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:19:41.599605   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:19:41.599642   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:41.599661   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:19:41.599905   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:19:41.599930   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:19:41.600025   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:19:41.600058   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:19:41.600110   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:19:41.600142   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 21.221483333s
I1129 14:19:41.600209   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:19:41.600248   95247 static_autoscaler.go:647] Starting scale down
I1129 14:19:41.600286   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 21.221483333s
I1129 14:19:41.600359   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:50.722542   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineDeployment total 19 items received
I1129 14:19:52.048520   95247 static_autoscaler.go:306] Starting main loop
I1129 14:19:52.048781   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:52.048843   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:19:52.049806   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:52.049838   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:52.049883   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:52.050782   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:52.050805   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:52.050826   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:52.051480   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:19:52.051506   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:19:52.051528   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:19:52.052105   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:19:52.053079   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:52.053217   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:19:52.054209   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:19:52.054469   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-8601349819209343059-upcoming-0
I1129 14:19:52.054592   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-6374888012270004227-upcoming-0
I1129 14:19:52.054616   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:19:52.054637   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:19:52.054651   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:19:52.054659   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:19:52.054693   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:19:52.054730   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:19:52.054788   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:19:52.054808   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:19:52.055027   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:19:52.055053   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:19:52.055164   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:19:52.055200   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:19:52.055259   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:19:52.055293   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 31.676177083s
I1129 14:19:52.055376   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:19:52.055432   95247 static_autoscaler.go:647] Starting scale down
I1129 14:19:52.055483   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 31.676177083s
I1129 14:19:52.055577   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:02.508181   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:02.508533   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:02.508600   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:02.510890   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:02.511734   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:02.511759   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:02.511783   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:02.512332   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:02.512353   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:02.512371   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:02.513307   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:02.513473   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:20:02.514363   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:02.514638   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5609883113199773598-upcoming-0
I1129 14:20:02.514767   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-9063227461240637110-upcoming-0
I1129 14:20:02.514800   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:20:02.514824   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:20:02.514837   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:02.514847   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:02.514904   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:02.514937   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:02.514976   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:02.514994   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:02.515266   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:02.515293   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:02.515398   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:20:02.515430   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:02.515493   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:02.515546   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 42.135940958s
I1129 14:20:02.515631   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:02.515700   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:02.515748   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 42.135940958s
I1129 14:20:02.515835   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:13.028191   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:13.028472   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:13.028550   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:13.031059   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:13.031806   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:13.031845   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-84-58.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:20:13.031870   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:13.032443   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:13.032464   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:13.032490   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:13.033255   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:13.034190   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:13.034428   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-4970155972811785032-upcoming-0
I1129 14:20:13.034577   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-5677364304254476994-upcoming-0
I1129 14:20:13.034614   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:20:13.034636   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:20:13.034649   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:13.034659   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:13.034701   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:13.034733   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:13.034775   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:13.034790   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:13.035018   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:13.035043   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:13.035143   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:20:13.035178   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:13.035229   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:13.035259   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 52.656037708s
I1129 14:20:13.035328   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:13.035369   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:13.035409   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 52.656037708s
I1129 14:20:13.035470   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:14.342597   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIDriver total 0 items received
I1129 14:20:17.342730   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolumeClaim total 0 items received
I1129 14:20:23.484486   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:23.484824   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:23.484901   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:23.487469   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:23.488197   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:23.488225   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:23.488249   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:23.488925   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:23.488952   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-130-47.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7839008Ki
I1129 14:20:23.488977   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:23.489814   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:23.490748   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:23.490959   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6v2lc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7545937751273795773-upcoming-0
I1129 14:20:23.491070   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-4x7jt can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-9079716988901546803-upcoming-0
I1129 14:20:23.491135   95247 filter_out_schedulable.go:123] 2 pods marked as unschedulable can be scheduled.
I1129 14:20:23.491155   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:20:23.491169   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:23.491175   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:23.491205   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:23.491227   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:23.491254   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:23.491268   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:23.491477   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:23.491496   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:23.491585   95247 eligibility.go:162] Node ip-10-180-13-238.eu-west-1.compute.internal unremovable: cpu requested (72.5521% of allocatable) is above the scale-down utilization threshold
I1129 14:20:23.491615   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:23.491657   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:23.491695   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 1m3.112411292s
I1129 14:20:23.491763   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:23.491804   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:23.491841   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m3.112411292s
I1129 14:20:23.491899   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:33.938056   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:33.938421   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:33.938493   95247 taints.go:442] Overriding status of node ip-10-180-84-58.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:20:33.938534   95247 taints.go:442] Overriding status of node ip-10-180-130-47.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:20:33.938574   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:33.941573   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:33.942370   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:33.942395   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:33.942424   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:33.943090   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:33.943112   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:33.943132   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:33.943960   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:33.945013   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:33.945039   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:20:33.945060   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:20:33.945072   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:33.945081   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:33.945115   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:33.945146   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:33.945206   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:33.945223   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:33.945463   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:33.945493   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:33.945606   95247 eligibility.go:167] Node ip-10-180-13-238.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:33.945622   95247 klogx.go:87] Node ip-10-180-13-238.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:33.945648   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:33.945710   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:33.945765   95247 cluster.go:156] Simulating node ip-10-180-13-238.eu-west-1.compute.internal removal
I1129 14:20:33.945821   95247 cluster.go:174] node ip-10-180-13-238.eu-west-1.compute.internal may be removed
I1129 14:20:33.945869   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 1m13.566057458s
I1129 14:20:33.945900   95247 nodes.go:84] ip-10-180-13-238.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:33.93798 +0530 IST m=+351.629791376 duration 0s
I1129 14:20:33.945982   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:33.946035   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:33.946082   95247 nodes.go:126] ip-10-180-13-238.eu-west-1.compute.internal was unneeded for 0s
I1129 14:20:33.946115   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m13.566057458s
I1129 14:20:33.946221   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:34.174637   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-13-238.eu-west-1.compute.internal
I1129 14:20:44.622123   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:44.622510   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:44.622572   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:44.624155   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:20:44.636364   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:44.637576   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:44.637604   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:44.637615   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:44.638029   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:44.638049   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:44.638061   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:44.638551   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:44.638593   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z2 finished successfully in 1m35.500515083s
I1129 14:20:44.638605   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z1 finished successfully in 1m34.909498583s
I1129 14:20:44.638650   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:44.638669   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:20:44.638676   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:20:44.638682   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:44.638685   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:44.638700   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:44.638708   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:44.638721   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:44.638727   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:44.638940   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:44.638957   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:44.639009   95247 eligibility.go:167] Node ip-10-180-13-238.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:44.639014   95247 klogx.go:87] Node ip-10-180-13-238.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:44.639056   95247 eligibility.go:167] Node ip-10-180-130-47.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:44.639060   95247 klogx.go:87] Node ip-10-180-130-47.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:44.639104   95247 eligibility.go:167] Node ip-10-180-84-58.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:44.639108   95247 klogx.go:87] Node ip-10-180-84-58.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:44.639121   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:44.639147   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:44.639159   95247 cluster.go:156] Simulating node ip-10-180-13-238.eu-west-1.compute.internal removal
I1129 14:20:44.639181   95247 cluster.go:174] node ip-10-180-13-238.eu-west-1.compute.internal may be removed
I1129 14:20:44.639193   95247 cluster.go:156] Simulating node ip-10-180-130-47.eu-west-1.compute.internal removal
I1129 14:20:44.639210   95247 cluster.go:174] node ip-10-180-130-47.eu-west-1.compute.internal may be removed
I1129 14:20:44.639218   95247 cluster.go:156] Simulating node ip-10-180-84-58.eu-west-1.compute.internal removal
I1129 14:20:44.639235   95247 cluster.go:174] node ip-10-180-84-58.eu-west-1.compute.internal may be removed
I1129 14:20:44.639246   95247 nodes.go:84] ip-10-180-130-47.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:44.622062 +0530 IST m=+362.313958376 duration 0s
I1129 14:20:44.639263   95247 nodes.go:84] ip-10-180-84-58.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:44.622062 +0530 IST m=+362.313958376 duration 0s
I1129 14:20:44.639266   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 1m24.250224458s
I1129 14:20:44.639269   95247 nodes.go:84] ip-10-180-13-238.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:33.93798 +0530 IST m=+351.629791376 duration 10.684167s
I1129 14:20:44.639313   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:44.639329   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:44.639352   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m24.250224458s
I1129 14:20:44.639362   95247 nodes.go:126] ip-10-180-13-238.eu-west-1.compute.internal was unneeded for 10.684167s
I1129 14:20:44.639375   95247 nodes.go:126] ip-10-180-130-47.eu-west-1.compute.internal was unneeded for 0s
I1129 14:20:44.639384   95247 nodes.go:126] ip-10-180-84-58.eu-west-1.compute.internal was unneeded for 0s
I1129 14:20:44.639399   95247 klogx.go:87] Considering node ip-10-180-13-238.eu-west-1.compute.internal for standard scale down
I1129 14:20:45.549695   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-13-238.eu-west-1.compute.internal
I1129 14:20:45.549903   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-13-238.eu-west-1.compute.internal"
I1129 14:20:45.549902   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-13-238.eu-west-1.compute.internal", UID:"45ae84ca-82df-4ebb-8648-9c5a39eaf38e", APIVersion:"v1", ResourceVersion:"10527", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:20:45.550410   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:20:45.776107   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10542", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-13-238.eu-west-1.compute.internal"
I1129 14:20:45.906778   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:20:45.907021   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 181.667Âµs
I1129 14:20:49.659458   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PodDisruptionBudget total 0 items received
I1129 14:20:49.660061   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSINode total 9 items received
I1129 14:20:49.660067   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicaSet total 8 items received
I1129 14:20:49.660070   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 85 items received
I1129 14:20:49.660148   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StatefulSet total 0 items received
I1129 14:20:49.660211   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Service total 4 items received
I1129 14:20:49.660353   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Pod total 193 items received
I1129 14:20:49.660406   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 85 items received
I1129 14:20:49.660415   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolume total 0 items received
I1129 14:20:49.660524   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicationController total 0 items received
I1129 14:20:49.660542   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.DaemonSet total 73 items received
I1129 14:20:49.660621   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIDriver total 0 items received
I1129 14:20:49.660644   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Job total 0 items received
I1129 14:20:49.660744   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Namespace total 2 items received
I1129 14:20:49.660766   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIStorageCapacity total 0 items received
I1129 14:20:49.660832   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StorageClass total 0 items received
I1129 14:20:49.660621   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolumeClaim total 0 items received
I1129 14:20:50.551906   95247 drain.go:131] All pods removed from ip-10-180-13-238.eu-west-1.compute.internal
I1129 14:20:50.552043   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-13-238.eu-west-1.compute.internal]
I1129 14:20:51.947368   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z3-7bb4b-26kdg marked with priority 1 successfully
I1129 14:20:51.947414   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z3-7bb4b-26kdg:ip-10-180-13-238.eu-west-1.compute.internal]
I1129 14:20:52.743101   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z3 size decreased to 0 
I1129 14:20:52.743359   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10692", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-13-238.eu-west-1.compute.internal removed
I1129 14:20:56.001759   95247 static_autoscaler.go:306] Starting main loop
I1129 14:20:56.002035   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:56.002100   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:20:56.003522   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:20:56.003542   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:20:56.004937   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:20:56.005865   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:56.005890   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:56.005915   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:56.006608   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:20:56.006629   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:20:56.006650   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:20:56.007311   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:56.007503   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:20:56.007526   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:20:56.007545   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:20:56.007555   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:20:56.007564   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:20:56.007598   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:20:56.007667   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:20:56.007719   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:20:56.007743   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:20:56.007801   95247 pre_filtering_processor.go:67] Skipping ip-10-180-13-238.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:20:56.008164   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:20:56.008201   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:20:56.008299   95247 eligibility.go:167] Node ip-10-180-84-58.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:56.008314   95247 klogx.go:87] Node ip-10-180-84-58.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:56.008401   95247 eligibility.go:167] Node ip-10-180-130-47.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:20:56.008414   95247 klogx.go:87] Node ip-10-180-130-47.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:20:56.008441   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:20:56.008501   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:20:56.008536   95247 cluster.go:156] Simulating node ip-10-180-84-58.eu-west-1.compute.internal removal
I1129 14:20:56.008582   95247 cluster.go:174] node ip-10-180-84-58.eu-west-1.compute.internal may be removed
I1129 14:20:56.008606   95247 cluster.go:156] Simulating node ip-10-180-130-47.eu-west-1.compute.internal removal
I1129 14:20:56.008654   95247 cluster.go:174] node ip-10-180-130-47.eu-west-1.compute.internal may be removed
I1129 14:20:56.008696   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:19:20.372566 +0530 IST m=+278.063733918 duration 1m35.629935875s
I1129 14:20:56.008727   95247 nodes.go:84] ip-10-180-84-58.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:44.622062 +0530 IST m=+362.313958376 duration 11.379711417s
I1129 14:20:56.008739   95247 nodes.go:84] ip-10-180-130-47.eu-west-1.compute.internal is unneeded since 2024-11-29 14:20:44.622062 +0530 IST m=+362.313958376 duration 11.379711417s
I1129 14:20:56.008834   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 14:20:44.622062 +0530 IST m=+362.313958376 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:20:56.008887   95247 static_autoscaler.go:647] Starting scale down
I1129 14:20:56.008937   95247 nodes.go:126] ip-10-180-130-47.eu-west-1.compute.internal was unneeded for 11.379711417s
I1129 14:20:56.008980   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m35.629935875s
I1129 14:20:56.009004   95247 nodes.go:126] ip-10-180-84-58.eu-west-1.compute.internal was unneeded for 11.379711417s
I1129 14:20:56.009058   95247 klogx.go:87] Considering node ip-10-180-130-47.eu-west-1.compute.internal for standard scale down
I1129 14:20:56.009081   95247 klogx.go:87] Considering node ip-10-180-84-58.eu-west-1.compute.internal for standard scale down
I1129 14:20:56.461802   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-130-47.eu-west-1.compute.internal
I1129 14:20:56.461985   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-130-47.eu-west-1.compute.internal", UID:"8f6f9d0f-bf69-43d3-9975-6e5eb0fea8f4", APIVersion:"v1", ResourceVersion:"10707", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:20:56.692394   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-84-58.eu-west-1.compute.internal
I1129 14:20:56.692477   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-130-47.eu-west-1.compute.internal"
I1129 14:20:56.692588   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-84-58.eu-west-1.compute.internal", UID:"86708446-307b-4d74-a1f5-6d3b720ae15b", APIVersion:"v1", ResourceVersion:"10724", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:20:56.692676   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-84-58.eu-west-1.compute.internal"
I1129 14:20:56.692844   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:20:56.693031   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:20:56.926003   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10692", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-130-47.eu-west-1.compute.internal"
I1129 14:20:57.154158   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10692", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-84-58.eu-west-1.compute.internal"
I1129 14:21:01.694611   95247 drain.go:131] All pods removed from ip-10-180-130-47.eu-west-1.compute.internal
I1129 14:21:01.694684   95247 drain.go:131] All pods removed from ip-10-180-84-58.eu-west-1.compute.internal
I1129 14:21:01.694760   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-84-58.eu-west-1.compute.internal]
I1129 14:21:01.694760   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-130-47.eu-west-1.compute.internal]
I1129 14:21:02.757430   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z1-745f9-vq9nn marked with priority 1 successfully
I1129 14:21:02.757487   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z1-745f9-vq9nn:ip-10-180-84-58.eu-west-1.compute.internal]
I1129 14:21:03.781842   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z2-967d8-ghkpt marked with priority 1 successfully
I1129 14:21:03.781887   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z2-967d8-ghkpt:ip-10-180-130-47.eu-west-1.compute.internal]
I1129 14:21:04.051112   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z1 size decreased to 1 
I1129 14:21:04.051328   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10789", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-84-58.eu-west-1.compute.internal removed
I1129 14:21:04.571013   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z2 size decreased to 0 
I1129 14:21:04.571199   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"10789", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-130-47.eu-west-1.compute.internal removed
I1129 14:21:07.146499   95247 static_autoscaler.go:306] Starting main loop
I1129 14:21:07.146742   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:07.146804   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:07.148210   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:21:07.148231   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:21:07.149576   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:21:07.150439   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:07.150469   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-84-58.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:21:07.150492   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:07.151063   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:07.151086   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-84-58.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:21:07.151105   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:07.151804   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:07.152001   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:21:07.152023   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:21:07.152044   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:21:07.152055   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:21:07.152064   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:21:07.152098   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:21:07.152130   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:21:07.152166   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:07.152182   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:21:07.152209   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:07.152231   95247 pre_filtering_processor.go:67] Skipping ip-10-180-13-238.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:21:07.152254   95247 pre_filtering_processor.go:67] Skipping ip-10-180-84-58.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:07.152271   95247 pre_filtering_processor.go:67] Skipping ip-10-180-130-47.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:21:07.152346   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:21:12.549233   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Deployment total 351 items received
I1129 14:21:17.604966   95247 static_autoscaler.go:306] Starting main loop
I1129 14:21:17.605383   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:17.605481   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:17.606925   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:21:17.607821   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:17.607848   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:17.607875   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:17.608514   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:17.608536   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:17.608556   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:17.609091   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:17.609111   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:17.609131   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:17.609886   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:17.610068   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:21:17.610091   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:21:17.610148   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:21:17.610167   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:21:17.610178   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:21:17.610214   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:21:17.610247   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:21:17.610306   95247 pre_filtering_processor.go:67] Skipping ip-10-180-84-58.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:17.610339   95247 pre_filtering_processor.go:67] Skipping ip-10-180-130-47.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:21:17.610363   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:17.610375   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:21:17.610399   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:17.610424   95247 pre_filtering_processor.go:67] Skipping ip-10-180-13-238.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:21:17.610507   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:21:28.093972   95247 static_autoscaler.go:306] Starting main loop
I1129 14:21:28.094339   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:28.094467   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:29.145055   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z2-967d8-ghkpt marked with priority 1 successfully
I1129 14:21:29.145949   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:21:29.146507   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:29.146521   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:29.146539   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:29.146908   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:29.146920   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:29.146932   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:29.147254   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:29.147266   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:29.147278   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:29.147664   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:29.147695   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:29.147704   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:29.147758   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0942388a22deca42f
I1129 14:21:29.147816   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:21:29.147839   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:29.147845   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:29.147877   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0942388a22deca42f, skipping
I1129 14:21:29.147925   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:21:29.147940   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:21:29.147953   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:21:29.147961   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:21:29.147965   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:21:29.147981   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:21:29.147998   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:21:29.148023   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:29.148033   95247 pre_filtering_processor.go:67] Skipping ip-10-180-84-58.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:29.148045   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:29.148051   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:21:29.148103   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:19:08.452558 +0530 IST m=+266.143565251 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:21:39.597875   95247 static_autoscaler.go:306] Starting main loop
I1129 14:21:39.598167   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:39.598242   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:39.599053   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:39.599081   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:39.599127   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:39.599887   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:39.599909   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:39.599930   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:39.600490   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:21:39.600990   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:39.601010   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:39.601028   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:39.601631   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:39.601655   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:21:39.601669   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:21:39.601687   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:21:39.601701   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:21:39.601712   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:21:39.601725   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:21:39.601739   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:39.601748   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:39.601758   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0942388a22deca42f
I1129 14:21:39.601826   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:21:39.601848   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:21:39.601860   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:21:39.601874   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:21:39.601887   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:39.601897   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:39.601907   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0942388a22deca42f, skipping
I1129 14:21:39.601924   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:21:39.601934   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:21:39.601945   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:21:39.601998   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:21:39.602218   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-qwwxs: cannot put pod scale-up-pod-6775c8dc87-qwwxs on any node
I1129 14:21:39.602257   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:21:39.602285   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:21:39.602297   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:21:39.602307   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:21:39.602328   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs is unschedulable
I1129 14:21:39.602370   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:21:39.602642   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-qwwxs can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:21:39.603062   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:21:39.603116   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-1505181238072687282 and template-node-for-shoot--i544000--ca-it-one-zone-z1-58636345606848908 are not similar, ephemeral-storage does not match
I1129 14:21:39.603749   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-6726108576439528547 and template-node-for-shoot--i544000--ca-it-one-zone-z1-58636345606848908 are not similar, ephemeral-storage does not match
I1129 14:21:39.604355   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-7235585272266225437 and template-node-for-shoot--i544000--ca-it-one-zone-z1-58636345606848908 are not similar, ephemeral-storage does not match
I1129 14:21:39.604874   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:21:39.604903   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:21:39.604916   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z3 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:21:39.604940   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z3
I1129 14:21:39.604960   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-three-zones-z3
I1129 14:21:39.605000   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-7235585272266225437 and template-node-for-shoot--i544000--ca-it-one-zone-z1-58636345606848908 are not similar, ephemeral-storage does not match
I1129 14:21:39.605086   95247 orchestrator.go:697] Found 2 similar node groups: [shoot--i544000--ca-it-three-zones-z1 shoot--i544000--ca-it-three-zones-z2]
I1129 14:21:39.605115   95247 orchestrator.go:713] Splitting scale-up between 3 similar node groups: {shoot--i544000--ca-it-three-zones-z3, shoot--i544000--ca-it-three-zones-z1, shoot--i544000--ca-it-three-zones-z2}
I1129 14:21:39.605156   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)}]
I1129 14:21:39.605190   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z3 size to 1
I1129 14:21:39.605233   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z3 by 1
I1129 14:21:40.459431   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W1129 14:21:40.459521   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z3
I1129 14:21:40.459745   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-qwwxs", UID:"766b9b9a-1f99-4fca-bef1-ea123e9772f1", APIVersion:"v1", ResourceVersion:"11089", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)}]
I1129 14:21:50.908369   95247 static_autoscaler.go:306] Starting main loop
I1129 14:21:50.908624   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:50.908692   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:21:50.909515   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:21:50.910305   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:50.910330   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:50.910397   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:50.910986   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:50.911009   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:50.911029   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:21:50.911623   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:21:50.911644   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:21:50.911663   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:21:50.912215   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z3
I1129 14:21:50.912311   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:50.912337   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:21:50.912351   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:21:50.912367   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:21:50.912397   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:21:50.912426   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:21:50.912440   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:21:50.912456   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:50.912466   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:50.912479   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0942388a22deca42f
I1129 14:21:50.912557   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:21:50.912586   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:21:50.912597   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:21:50.912610   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:21:50.912624   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:21:50.912633   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:21:50.912642   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:21:50.912658   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0942388a22deca42f"
I1129 14:21:50.912669   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0942388a22deca42f, it's either been removed or it's not managed by this controller
W1129 14:21:50.912679   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0942388a22deca42f, skipping
I1129 14:21:50.913143   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:21:50.913371   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-6312745810367628770-upcoming-0
I1129 14:21:50.913421   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:21:50.913445   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:21:50.913457   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:21:50.913466   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:21:50.913500   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:21:50.913532   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:21:50.913583   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:21:50.913609   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:21:50.913728   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:21:50.913848   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:01.376787   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:01.376998   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:01.377061   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:01.377884   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:01.378643   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:01.378669   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:01.378696   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:01.379252   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:01.379272   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:01.379291   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:01.379820   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:01.379839   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:01.379861   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:01.380506   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:01.380577   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:01.380590   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:01.380609   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:22:01.380625   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:01.380634   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:01.380647   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:22:01.380718   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:22:01.380754   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:01.380766   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:01.380779   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:22:01.380794   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:01.380804   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:01.380815   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:22:01.381227   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:01.381466   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-1564126657790562468-upcoming-0
I1129 14:22:01.381505   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:01.381527   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:01.381541   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:01.381550   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:01.381587   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:01.381618   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:01.381666   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:01.381684   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:01.381709   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:01.381798   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:11.836375   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:11.836642   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:11.836704   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:11.837565   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:11.837595   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:11.837638   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:11.838465   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:11.839079   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:11.839101   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:11.839120   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:11.839705   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:11.839723   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:11.839744   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:11.840487   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:11.840555   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:11.840570   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:11.840588   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:22:11.840606   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:11.840617   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:11.840629   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:22:11.840701   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:22:11.840742   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:11.840754   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:11.840773   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:22:11.840787   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:11.840799   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:11.840807   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:22:11.841289   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:11.841552   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-4760514544185403398-upcoming-0
I1129 14:22:11.841622   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:11.841650   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:11.841663   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:11.841673   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:11.841707   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:11.841739   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:11.841783   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:11.841804   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:11.841843   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:11.841928   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:15.718930   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineSet total 35 items received
I1129 14:22:22.366341   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:22.366652   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:22.366724   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:22.367476   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:22.368228   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:22.368255   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:22.368283   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:22.368925   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:22.368948   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:22.368967   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:22.369460   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:22.369479   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:22.369496   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:22.370212   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:22.370263   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:22.370277   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:22.370295   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:22:22.370332   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:22.370343   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:22.370357   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:22:22.370432   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:22:22.370469   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:22.370480   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:22.370497   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:22:22.370511   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:22.370519   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:22.370529   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:22:22.370985   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:22.371200   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-2838002867491405852-upcoming-0
I1129 14:22:22.371223   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:22.371242   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:22.371255   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:22.371266   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:22.371299   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:22.371337   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:22.371414   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:22.371441   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:22.371473   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:22.371560   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:32.821985   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:32.822271   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:32.822337   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:32.823036   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:32.823703   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:32.823724   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:32.823748   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:32.824202   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:32.824218   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:32.824231   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:32.824765   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:32.824782   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:32.824795   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:32.825370   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:32.825424   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:32.825437   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:32.825451   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:22:32.825462   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:32.825469   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:32.825480   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:22:32.825540   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:22:32.825558   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:32.825566   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:32.825576   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:22:32.825588   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:32.825594   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:32.825602   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:22:32.825938   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:32.826131   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-4563699263919974144-upcoming-0
I1129 14:22:32.826161   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:32.826179   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:32.826189   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:32.826195   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:32.826220   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:32.826242   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:32.826279   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:32.826295   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:32.826316   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:32.826381   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:43.279493   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:43.279705   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:43.279763   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:43.280753   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:43.280781   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:43.280826   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:43.281580   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:43.281599   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-2-97.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925028Ki
I1129 14:22:43.281620   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:43.282224   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:43.282761   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:43.282782   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:43.282802   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:43.283487   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:43.283548   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:43.283564   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:43.283583   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-0a65f5ff67cc7c557
I1129 14:22:43.283599   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:43.283611   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:43.283624   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-01a134ba85b88ddf5
I1129 14:22:43.283696   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:22:43.283718   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-0a65f5ff67cc7c557"
I1129 14:22:43.283765   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-0a65f5ff67cc7c557, it's either been removed or it's not managed by this controller
W1129 14:22:43.283785   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-0a65f5ff67cc7c557, skipping
I1129 14:22:43.283807   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-01a134ba85b88ddf5"
I1129 14:22:43.283819   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-01a134ba85b88ddf5, it's either been removed or it's not managed by this controller
W1129 14:22:43.283830   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-01a134ba85b88ddf5, skipping
I1129 14:22:43.284324   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:43.284580   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-4667763670767643680-upcoming-0
I1129 14:22:43.284612   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:43.284631   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:43.284643   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:43.284652   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:43.284685   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:43.284715   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:43.284754   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:43.284771   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:43.284799   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:43.284874   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:22:45.906837   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:22:45.907056   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 145.625Âµs
I1129 14:22:53.958306   95247 static_autoscaler.go:306] Starting main loop
I1129 14:22:53.958551   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:53.958633   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:22:53.959701   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:53.959732   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:53.959776   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:53.960640   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:53.960663   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:53.960683   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:53.961482   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:22:53.961518   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:22:53.961540   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:22:53.962190   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:22:53.962905   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:53.963479   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:22:53.963699   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-2145201789931847583-upcoming-0
I1129 14:22:53.963743   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:22:53.963766   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:22:53.963779   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:22:53.963789   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:22:53.963823   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:22:53.963854   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:22:53.963898   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:22:53.963918   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:22:53.963945   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:22:53.964022   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:23:04.414660   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:04.414967   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:04.415034   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:04.416013   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:04.416864   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:04.416889   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:04.416913   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:04.417519   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:04.417540   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:04.417559   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:04.418105   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:04.418126   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:04.418146   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:04.418781   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:04.419299   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:04.419540   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-qwwxs can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-211780559272885416-upcoming-0
I1129 14:23:04.419582   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:23:04.419604   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:23:04.419617   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:04.419627   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:04.419661   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:04.419692   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:04.419740   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:04.419761   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:04.419791   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:04.419867   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:23:14.872714   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:14.873013   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:14.873098   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:14.873154   95247 taints.go:442] Overriding status of node ip-10-180-2-97.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:23:14.874087   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:14.874855   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:14.874881   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:14.874906   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:14.875541   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:14.875563   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:14.875582   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:14.876204   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:14.876232   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:14.876251   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:14.876895   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:14.877417   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:14.877440   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:23:14.877460   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:23:14.877472   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:14.877481   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:14.877515   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:14.877551   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:14.877583   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:14.877600   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:14.877627   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:14.877701   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:23:23.719072   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.Machine total 73 items received
I1129 14:23:25.475876   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:25.476202   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:25.476276   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:25.476332   95247 taints.go:442] Overriding status of node ip-10-180-2-97.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:23:25.477614   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:25.478458   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:25.478487   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:25.478515   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:25.479026   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:25.479042   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:25.479052   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:25.479455   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:25.479471   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:25.479482   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:25.479917   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:25.480348   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:25.480370   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:23:25.480384   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:23:25.480391   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:25.480415   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:25.480442   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:25.480736   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:25.480767   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:25.480778   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:25.480794   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:25.480865   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:23:33.717732   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineClass total 14 items received
I1129 14:23:35.932470   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:35.932728   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:35.932796   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:35.933763   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:35.933793   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:35.933835   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:35.934696   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:35.934720   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:35.934741   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:35.935293   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:35.935912   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:35.935933   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:35.935952   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:35.936638   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:35.936714   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z3 finished successfully in 1m55.474018583s
I1129 14:23:35.936808   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:35.936830   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:23:35.936851   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:23:35.936862   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:35.936871   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:35.936904   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:35.936938   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:35.936970   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:35.936986   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:35.937008   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:35.937059   95247 eligibility.go:119] Skipping ip-10-180-2-97.eu-west-1.compute.internal from delete consideration - the node is marked as no scale down
I1129 14:23:35.937124   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:23:35.937196   95247 static_autoscaler.go:647] Starting scale down
I1129 14:23:35.937295   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:35.937362   95247 taints.go:317] Releasing taint {Key:DeletionCandidateOfClusterAutoscaler Value:1732870160 Effect:PreferNoSchedule TimeAdded:<nil>} on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:23:36.412520   95247 taints.go:352] Successfully released DeletionCandidateOfClusterAutoscaler on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:23:46.995276   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:46.995583   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:46.995662   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:46.996622   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:46.996652   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:46.996693   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:46.997574   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:46.997603   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:46.997632   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:46.998285   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:46.998309   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:46.998328   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:46.998932   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:46.999613   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:46.999778   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:46.999802   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:23:46.999823   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:23:46.999835   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:46.999845   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:46.999881   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:46.999914   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:46.999949   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:46.999970   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:46.999999   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:47.000155   95247 eligibility.go:167] Node ip-10-180-2-97.eu-west-1.compute.internal is underutilized: cpu requested (20.625% of allocatable) is below the scale-down utilization threshold
I1129 14:23:47.000186   95247 klogx.go:87] Node ip-10-180-2-97.eu-west-1.compute.internal - cpu requested is 20.625% of allocatable
I1129 14:23:47.000218   95247 cluster.go:156] Simulating node ip-10-180-2-97.eu-west-1.compute.internal removal
I1129 14:23:47.000300   95247 cluster.go:174] node ip-10-180-2-97.eu-west-1.compute.internal may be removed
I1129 14:23:47.000339   95247 nodes.go:84] ip-10-180-2-97.eu-west-1.compute.internal is unneeded since 2024-11-29 14:23:46.995158 +0530 IST m=+544.688508626 duration 0s
I1129 14:23:47.000425   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:23:47.000479   95247 static_autoscaler.go:647] Starting scale down
I1129 14:23:47.000525   95247 nodes.go:126] ip-10-180-2-97.eu-west-1.compute.internal was unneeded for 0s
I1129 14:23:47.000609   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:47.451686   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-2-97.eu-west-1.compute.internal
I1129 14:23:57.901214   95247 static_autoscaler.go:306] Starting main loop
I1129 14:23:57.901434   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:57.901497   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:23:57.902489   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:23:57.903309   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:57.903335   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:57.903363   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:57.904157   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:57.904187   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:57.904213   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:57.904796   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:23:57.904819   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:23:57.904842   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:23:57.905558   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:57.905704   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:23:57.905727   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:23:57.905747   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:23:57.905759   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:23:57.905768   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:23:57.905803   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:23:57.905838   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:23:57.905874   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:23:57.905895   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:23:57.905919   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:23:57.906078   95247 eligibility.go:167] Node ip-10-180-2-97.eu-west-1.compute.internal is underutilized: cpu requested (20.625% of allocatable) is below the scale-down utilization threshold
I1129 14:23:57.906118   95247 klogx.go:87] Node ip-10-180-2-97.eu-west-1.compute.internal - cpu requested is 20.625% of allocatable
I1129 14:23:57.906148   95247 cluster.go:156] Simulating node ip-10-180-2-97.eu-west-1.compute.internal removal
I1129 14:23:57.906225   95247 cluster.go:174] node ip-10-180-2-97.eu-west-1.compute.internal may be removed
I1129 14:23:57.906267   95247 nodes.go:84] ip-10-180-2-97.eu-west-1.compute.internal is unneeded since 2024-11-29 14:23:46.995158 +0530 IST m=+544.688508626 duration 10.905984375s
I1129 14:23:57.906349   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:20:56.001683 +0530 IST m=+373.693669793 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:23:57.906418   95247 static_autoscaler.go:647] Starting scale down
I1129 14:23:57.906462   95247 nodes.go:126] ip-10-180-2-97.eu-west-1.compute.internal was unneeded for 10.905984375s
I1129 14:23:57.906514   95247 klogx.go:87] Considering node ip-10-180-2-97.eu-west-1.compute.internal for standard scale down
I1129 14:23:58.347714   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-2-97.eu-west-1.compute.internal
I1129 14:23:58.347788   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-2-97.eu-west-1.compute.internal"
I1129 14:23:58.347883   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-2-97.eu-west-1.compute.internal", UID:"0815ce82-8ff2-4bcd-a53e-f7e819a5f109", APIVersion:"v1", ResourceVersion:"12367", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:23:58.348062   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:23:58.579219   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12372", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-2-97.eu-west-1.compute.internal"
I1129 14:24:03.349384   95247 drain.go:131] All pods removed from ip-10-180-2-97.eu-west-1.compute.internal
I1129 14:24:03.349513   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-2-97.eu-west-1.compute.internal]
I1129 14:24:04.398457   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z3-7bb4b-h6xvp marked with priority 1 successfully
I1129 14:24:04.398515   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z3-7bb4b-h6xvp:ip-10-180-2-97.eu-west-1.compute.internal]
I1129 14:24:05.230752   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z3 size decreased to 0 
I1129 14:24:05.230960   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12449", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: empty node ip-10-180-2-97.eu-west-1.compute.internal removed
I1129 14:24:08.807869   95247 static_autoscaler.go:306] Starting main loop
I1129 14:24:08.808243   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:08.808317   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:08.809346   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:24:08.809366   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:24:08.810576   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:24:08.811386   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:08.811410   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:08.811445   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:08.812074   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:08.812094   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:08.812115   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:08.812670   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:08.812809   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:24:08.812832   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:24:08.812852   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:24:08.812864   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:24:08.812873   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:24:08.812905   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:24:08.812936   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:24:08.812970   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:08.812987   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:24:08.813015   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:24:08.813039   95247 pre_filtering_processor.go:67] Skipping ip-10-180-2-97.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:24:08.813118   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:24:19.267271   95247 static_autoscaler.go:306] Starting main loop
I1129 14:24:19.267495   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:19.267557   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:19.268494   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:24:19.268515   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:24:19.269678   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:24:19.270421   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:19.270445   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:19.270517   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:19.271184   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:19.271209   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:19.271235   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:19.271808   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:19.271952   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:24:19.271976   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:24:19.271996   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:24:19.272007   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:24:19.272016   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:24:19.272049   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:24:19.272081   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:24:19.272114   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:19.272134   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:24:19.272159   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:24:19.272180   95247 pre_filtering_processor.go:67] Skipping ip-10-180-2-97.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:24:19.272259   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:24:29.964750   95247 static_autoscaler.go:306] Starting main loop
I1129 14:24:29.965127   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:29.965223   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:29.966280   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:29.966315   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:29.966353   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:29.967231   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:29.967253   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:29.967279   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:29.967860   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:24:29.968405   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:29.968426   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:29.968445   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:29.969008   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:29.969171   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:24:29.969193   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:24:29.969213   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:24:29.969224   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:24:29.969233   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:24:29.969267   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:24:29.969298   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:24:29.969331   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:29.969347   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:24:29.969374   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:24:29.969399   95247 pre_filtering_processor.go:67] Skipping ip-10-180-2-97.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:24:29.969476   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:21:39.597798 +0530 IST m=+417.290132418 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:24:40.432949   95247 static_autoscaler.go:306] Starting main loop
I1129 14:24:40.433098   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:40.433152   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:40.433732   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:24:40.434320   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:40.434334   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:40.434351   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:40.434695   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:40.434705   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:40.434717   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:40.435161   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:40.435182   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:40.435200   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:40.435808   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:40.435867   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0dbe7b20e9f8400f5"
I1129 14:24:40.435880   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0dbe7b20e9f8400f5, it's either been removed or it's not managed by this controller
W1129 14:24:40.435898   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0dbe7b20e9f8400f5
I1129 14:24:40.435974   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:24:40.435999   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0dbe7b20e9f8400f5"
I1129 14:24:40.436011   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0dbe7b20e9f8400f5, it's either been removed or it's not managed by this controller
W1129 14:24:40.436025   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0dbe7b20e9f8400f5, skipping
I1129 14:24:40.436098   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:24:40.436322   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-6tprc: cannot put pod scale-up-pod-6775c8dc87-6tprc on any node
I1129 14:24:40.436506   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-tq97q based on similar pods scheduling
I1129 14:24:40.436598   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-psscj based on similar pods scheduling
I1129 14:24:40.436682   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff based on similar pods scheduling
I1129 14:24:40.436779   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:24:40.436867   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:24:40.436945   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:24:40.437041   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:24:40.437060   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:24:40.437083   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:24:40.437095   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:24:40.437114   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 8 unschedulable pods left
I1129 14:24:40.437147   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc is unschedulable
I1129 14:24:40.437157   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q is unschedulable
I1129 14:24:40.437165   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj is unschedulable
I1129 14:24:40.437172   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:24:40.437178   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:24:40.437185   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:24:40.437191   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:24:40.437198   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:24:40.437516   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:24:40.437826   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-6tprc can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:24:40.437839   95247 orchestrator.go:597] 7 other pods similar to scale-up-pod-6775c8dc87-6tprc can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:24:40.438013   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-2256079302801990096 and template-node-for-shoot--i544000--ca-it-one-zone-z1-6457797392647423149 are not similar, ephemeral-storage does not match
I1129 14:24:40.438997   95247 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I1129 14:24:40.439036   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:24:40.439111   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-6169124020825566238 and template-node-for-shoot--i544000--ca-it-one-zone-z1-6457797392647423149 are not similar, ephemeral-storage does not match
I1129 14:24:40.440500   95247 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I1129 14:24:40.440547   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-6463054686423323553 and template-node-for-shoot--i544000--ca-it-one-zone-z1-6457797392647423149 are not similar, ephemeral-storage does not match
I1129 14:24:40.441387   95247 threshold_based_limiter.go:59] Capping binpacking after exceeding threshold of 3 nodes
I1129 14:24:40.441410   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z3 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:24:40.441430   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:24:40.441437   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:24:40.441451   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z1
I1129 14:24:40.441461   95247 orchestrator.go:190] Estimated 3 nodes needed in shoot--i544000--ca-it-three-zones-z1
I1129 14:24:40.441517   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-6169124020825566238 and template-node-for-shoot--i544000--ca-it-one-zone-z1-6457797392647423149 are not similar, ephemeral-storage does not match
I1129 14:24:40.441550   95247 orchestrator.go:697] Found 2 similar node groups: [shoot--i544000--ca-it-three-zones-z3 shoot--i544000--ca-it-three-zones-z2]
I1129 14:24:40.441569   95247 orchestrator.go:713] Splitting scale-up between 3 similar node groups: {shoot--i544000--ca-it-three-zones-z1, shoot--i544000--ca-it-three-zones-z3, shoot--i544000--ca-it-three-zones-z2}
I1129 14:24:40.441594   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:24:40.441619   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z3 size to 1
I1129 14:24:40.441651   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z3 by 1
I1129 14:24:40.441919   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z3 size to 1 instead of 0 (max: 1)
I1129 14:24:41.229713   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1
I1129 14:24:41.229758   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z2 by 1
I1129 14:24:41.229947   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z3 size set to 1 instead of 0 (max: 1)
I1129 14:24:41.458253   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1 instead of 0 (max: 1)
I1129 14:24:41.825900   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z1 size to 2
I1129 14:24:41.825996   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z1 by 1
I1129 14:24:41.826690   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z2 size set to 1 instead of 0 (max: 1)
I1129 14:24:42.052076   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z1 size to 2 instead of 1 (max: 2)
I1129 14:24:42.428380   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I1129 14:24:42.428676   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"12674", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z1 size set to 2 instead of 1 (max: 2)
I1129 14:24:42.661221   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-6tprc", UID:"693acbf1-9486-4505-916d-1692d5513937", APIVersion:"v1", ResourceVersion:"12711", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:24:42.885782   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-tq97q", UID:"a30886da-a42a-4848-ae61-5d4610874d7d", APIVersion:"v1", ResourceVersion:"12718", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:24:43.110580   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-psscj", UID:"4dd36dc8-a2f4-49c2-8ad2-2c09528e41ab", APIVersion:"v1", ResourceVersion:"12715", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z3 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)} {shoot--i544000--ca-it-three-zones-z1 1->2 (max: 2)}]
I1129 14:24:45.906478   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:24:45.906737   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 185.333Âµs
I1129 14:24:52.880081   95247 static_autoscaler.go:306] Starting main loop
I1129 14:24:52.880388   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:52.880501   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:24:52.881534   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:24:52.882490   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:52.882532   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:52.882618   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:52.883421   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:52.883450   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:52.883471   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:52.884406   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:24:52.884427   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:24:52.884446   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:24:52.885292   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:52.885477   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:24:52.886817   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:24:52.887035   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-4431359429794148320-upcoming-0
I1129 14:24:52.887130   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-6125986173236409927-upcoming-0
I1129 14:24:52.887220   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-3605842852155078304-upcoming-0
I1129 14:24:52.887338   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff: cannot put pod scale-up-pod-6775c8dc87-lg6ff on any node
I1129 14:24:52.887636   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:24:52.887733   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:24:52.887816   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:24:52.887901   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:24:52.887922   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:24:52.887943   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:24:52.887956   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:24:52.887969   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:24:52.887990   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:24:52.887998   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:24:52.888005   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:24:52.888012   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:24:52.888018   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:24:52.888308   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:24:52.888370   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:24:52.888387   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:24:52.888396   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:24:52.888569   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:24:52.888590   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:24:52.888617   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:24:52.888658   95247 orchestrator.go:169] No expansion options
I1129 14:24:52.888792   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:24:52.888841   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:52.888857   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:24:52.888846   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-lg6ff", UID:"244e1cc1-9f2a-444e-adfb-d08180f037af", APIVersion:"v1", ResourceVersion:"12707", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:24:52.889014   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:24:52.889042   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:24:52.889070   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:24:52.889151   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:24:52.889195   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 0s
I1129 14:24:52.889277   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:24:52.889333   95247 static_autoscaler.go:647] Starting scale down
I1129 14:24:52.889381   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 0s
I1129 14:24:52.889472   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:24:53.115096   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-9nkn9", UID:"db3b3dda-0311-4f69-8fd6-66b0653b49fe", APIVersion:"v1", ResourceVersion:"12719", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:24:53.335627   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:24:53.557362   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-gm78j", UID:"e334b6c6-2432-42de-b8a4-cc5f8c57fd99", APIVersion:"v1", ResourceVersion:"12713", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:24:53.780727   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-kx7g2", UID:"69c093f5-f9a1-4325-9b07-25f79f9ca8a9", APIVersion:"v1", ResourceVersion:"12701", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:24:54.005662   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-rx27n", UID:"16f1907e-01cd-4420-92b9-cd405a323ffa", APIVersion:"v1", ResourceVersion:"12704", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 3 max node group size reached, 1 node(s) didn't match Pod's node affinity/selector
I1129 14:25:03.785501   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:03.785855   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:03.785952   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:03.786914   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:03.786942   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:03.786982   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:03.787876   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:03.788484   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:03.788505   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:03.788532   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:03.789184   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:03.789205   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:03.789223   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:03.789942   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:03.790130   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:25:03.791332   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:03.791551   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-5366294367821663742-upcoming-0
I1129 14:25:03.791697   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-6889437428254597975-upcoming-0
I1129 14:25:03.791831   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-2623190856057145150-upcoming-0
I1129 14:25:03.791971   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff: cannot put pod scale-up-pod-6775c8dc87-lg6ff on any node
I1129 14:25:03.792155   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:25:03.792243   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:25:03.792339   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:25:03.792424   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:03.792445   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:03.792467   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:03.792480   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:03.792494   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:03.792516   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:25:03.792525   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:25:03.792534   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:25:03.792543   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:03.792549   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:03.792869   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:03.792932   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:03.792947   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:03.792973   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:03.793211   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:03.793237   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:03.793265   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:03.793282   95247 orchestrator.go:169] No expansion options
I1129 14:25:03.793418   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:03.793464   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:03.793480   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:03.793622   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:03.793648   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:03.793679   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:03.793757   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:03.793795   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 10.905511042s
I1129 14:25:03.793883   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:03.793937   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:03.793984   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 10.905511042s
I1129 14:25:03.794061   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:14.246509   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:14.246831   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:14.246906   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:14.247940   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:14.248779   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:14.248809   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:14.248836   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:14.249475   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:14.249495   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:14.249514   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:14.250059   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:14.250079   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:14.250096   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:14.250896   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:14.251052   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:25:14.252260   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:14.252477   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-3691106894695236746-upcoming-0
I1129 14:25:14.252621   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5941741242414299876-upcoming-0
I1129 14:25:14.252758   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-6460206121990855511-upcoming-0
I1129 14:25:14.252889   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j: cannot put pod scale-up-pod-6775c8dc87-gm78j on any node
I1129 14:25:14.253059   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:25:14.253145   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:14.253232   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-6tprc based on similar pods scheduling
I1129 14:25:14.253316   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-tq97q based on similar pods scheduling
I1129 14:25:14.253337   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:14.253358   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:14.253371   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:14.253384   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:14.253406   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:25:14.253414   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:14.253421   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:14.253427   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc is unschedulable
I1129 14:25:14.253433   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q is unschedulable
I1129 14:25:14.253739   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:14.253784   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:14.253801   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:14.253829   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:14.254013   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-gm78j can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:14.254033   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-gm78j can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:14.254060   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:14.254077   95247 orchestrator.go:169] No expansion options
I1129 14:25:14.254194   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:14.254246   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:14.254265   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:14.254386   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:14.254411   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:14.254436   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:14.254505   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:14.254536   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 21.366601209s
I1129 14:25:14.254600   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:14.254640   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:14.254672   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 21.366601209s
I1129 14:25:14.254745   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:14.254844   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-6tprc", UID:"693acbf1-9486-4505-916d-1692d5513937", APIVersion:"v1", ResourceVersion:"12711", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:25:14.510687   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-tq97q", UID:"a30886da-a42a-4848-ae61-5d4610874d7d", APIVersion:"v1", ResourceVersion:"12718", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:25:24.818467   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:24.818803   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:24.818876   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:24.819685   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:24.820520   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:24.820545   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:24.820571   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:24.821226   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:24.821250   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:24.821271   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:24.821835   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:24.821856   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:24.821875   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:24.822634   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:24.822845   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:25:24.824108   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:24.824337   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5605321106850952031-upcoming-0
I1129 14:25:24.824463   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-4782721525779437549-upcoming-0
I1129 14:25:24.824588   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-1401201196902665247-upcoming-0
I1129 14:25:24.824768   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff: cannot put pod scale-up-pod-6775c8dc87-lg6ff on any node
I1129 14:25:24.824946   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:25:24.825038   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:25:24.825127   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:25:24.825220   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:24.825243   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:24.825263   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:24.825277   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:24.825292   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:24.825316   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:25:24.825331   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:25:24.825340   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:24.825348   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:25:24.825356   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:24.825666   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:24.825728   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:24.825742   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:24.825751   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:24.825946   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:24.825968   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:24.825993   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:24.826010   95247 orchestrator.go:169] No expansion options
I1129 14:25:24.826135   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:24.826177   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:24.826193   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:24.826335   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:24.826360   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:24.826390   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:24.826509   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:24.826549   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 31.938648709s
I1129 14:25:24.826628   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:24.826685   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:24.826732   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 31.938648709s
I1129 14:25:24.826814   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:35.287779   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:35.288092   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:35.288176   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:35.289034   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:35.289063   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:35.289107   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:35.289869   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:35.289891   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:35.289911   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:35.290519   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:35.291105   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:35.291126   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:35.291147   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:35.291887   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:35.292091   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:25:35.293450   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:35.293657   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-3410792225285810684-upcoming-0
I1129 14:25:35.293776   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-2578916275469596718-upcoming-0
I1129 14:25:35.293922   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-962712734508857058-upcoming-0
I1129 14:25:35.294065   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff: cannot put pod scale-up-pod-6775c8dc87-lg6ff on any node
I1129 14:25:35.294275   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:25:35.294365   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:25:35.294450   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:25:35.294535   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:35.294556   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:35.294577   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:35.294590   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:35.294604   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:35.294626   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:25:35.294635   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:25:35.294642   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:35.294648   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:25:35.294656   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:35.294990   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:35.295044   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:35.295058   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:35.295092   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:35.295295   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:35.295313   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:35.295338   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:35.295355   95247 orchestrator.go:169] No expansion options
I1129 14:25:35.295467   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:35.295503   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:35.295521   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:35.295657   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:35.295681   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:35.295709   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:35.295783   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:35.295818   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 42.407909459s
I1129 14:25:35.295900   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:35.295953   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:35.295987   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 42.407909459s
I1129 14:25:35.296053   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:46.789660   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:46.790005   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:46.790078   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:46.791360   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:46.791395   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:46.791435   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:46.792248   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:46.792272   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:46.792292   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:46.792852   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:46.792876   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-79-35.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925028Ki
I1129 14:25:46.792894   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:46.793423   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:46.794213   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:46.795484   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:46.795704   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-9099145360042135630-upcoming-0
I1129 14:25:46.795859   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7382395125022502108-upcoming-0
I1129 14:25:46.795964   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-2236434241849155466-upcoming-0
I1129 14:25:46.796084   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff: cannot put pod scale-up-pod-6775c8dc87-lg6ff on any node
I1129 14:25:46.796249   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-9nkn9 based on similar pods scheduling
I1129 14:25:46.796333   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-gm78j based on similar pods scheduling
I1129 14:25:46.796412   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2 based on similar pods scheduling
I1129 14:25:46.796494   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:46.796516   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:46.796537   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:46.796550   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:46.796563   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:46.796584   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:25:46.796593   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 is unschedulable
I1129 14:25:46.796599   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j is unschedulable
I1129 14:25:46.796606   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:46.796612   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:46.796907   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:46.796967   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:46.796983   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:46.796992   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:46.797181   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:46.797201   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-lg6ff can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:46.797224   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:46.797240   95247 orchestrator.go:169] No expansion options
I1129 14:25:46.797355   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:46.797399   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:46.797414   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:46.797553   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:46.797579   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:46.797609   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:46.797684   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:46.797720   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 53.91001s
I1129 14:25:46.797803   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:46.797858   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:46.797902   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 53.91001s
I1129 14:25:46.797986   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:57.250376   95247 static_autoscaler.go:306] Starting main loop
I1129 14:25:57.250673   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:57.250746   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:25:57.251993   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:57.252024   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-79-35.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925028Ki
I1129 14:25:57.252063   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:57.252868   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:57.252896   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:57.252926   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:57.253499   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:25:57.254032   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:25:57.254054   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:25:57.254074   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:25:57.254869   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:57.256182   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:25:57.256403   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-5063816601554501893-upcoming-0
I1129 14:25:57.256629   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-2824211657592492005-upcoming-0
I1129 14:25:57.256800   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-7173602794140983521-upcoming-0
I1129 14:25:57.256957   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-kx7g2: cannot put pod scale-up-pod-6775c8dc87-kx7g2 on any node
I1129 14:25:57.257358   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n based on similar pods scheduling
I1129 14:25:57.257471   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-tq97q based on similar pods scheduling
I1129 14:25:57.257565   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-6tprc based on similar pods scheduling
I1129 14:25:57.257657   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-psscj based on similar pods scheduling
I1129 14:25:57.257679   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:25:57.257705   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:25:57.257720   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:25:57.257733   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:25:57.257755   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 is unschedulable
I1129 14:25:57.257762   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:25:57.257767   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q is unschedulable
I1129 14:25:57.257772   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc is unschedulable
I1129 14:25:57.257776   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj is unschedulable
I1129 14:25:57.258014   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:25:57.258072   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:25:57.258085   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:25:57.258093   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:25:57.258295   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-kx7g2 can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:25:57.258313   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-kx7g2 can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:25:57.258332   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:25:57.258345   95247 orchestrator.go:169] No expansion options
I1129 14:25:57.258483   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:25:57.258540   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:25:57.258553   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:25:57.258696   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:25:57.258719   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:25:57.258745   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:25:57.258815   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:25:57.258845   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 1m4.370811709s
I1129 14:25:57.258922   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:25:57.258961   95247 static_autoscaler.go:647] Starting scale down
I1129 14:25:57.259001   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m4.370811709s
I1129 14:25:57.259045   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-6775c8dc87-psscj", UID:"4dd36dc8-a2f4-49c2-8ad2-2c09528e41ab", APIVersion:"v1", ResourceVersion:"12715", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 max node group size reached
I1129 14:25:57.259078   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:03.882679   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIDriver total 6 items received
I1129 14:26:03.888056   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Service total 6 items received
I1129 14:26:07.709575   95247 static_autoscaler.go:306] Starting main loop
I1129 14:26:07.709800   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:07.709874   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:07.709932   95247 taints.go:442] Overriding status of node ip-10-180-26-210.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:26:07.711214   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:07.711244   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:07.711291   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:07.712126   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:07.712149   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:07.712170   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:07.712750   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:26:07.713326   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:07.713349   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:07.713370   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:07.714096   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:07.715288   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:26:07.715509   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-9nkn9 can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z3-5064871685081385098-upcoming-0
I1129 14:26:07.715680   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-kx7g2 can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7013054772841131548-upcoming-0
I1129 14:26:07.715860   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-gm78j can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z1-2742608178293014892-upcoming-0
I1129 14:26:07.716033   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-rx27n: cannot put pod scale-up-pod-6775c8dc87-rx27n on any node
I1129 14:26:07.716204   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-6tprc based on similar pods scheduling
I1129 14:26:07.716294   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-tq97q based on similar pods scheduling
I1129 14:26:07.716377   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-psscj based on similar pods scheduling
I1129 14:26:07.716464   95247 klogx.go:87] failed to find place for default/scale-up-pod-6775c8dc87-lg6ff based on similar pods scheduling
I1129 14:26:07.716485   95247 filter_out_schedulable.go:123] 3 pods marked as unschedulable can be scheduled.
I1129 14:26:07.716507   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:26:07.716520   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:26:07.716533   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 5 unschedulable pods left
I1129 14:26:07.716555   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-rx27n is unschedulable
I1129 14:26:07.716564   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-6tprc is unschedulable
I1129 14:26:07.716571   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-tq97q is unschedulable
I1129 14:26:07.716578   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-psscj is unschedulable
I1129 14:26:07.716584   95247 klogx.go:87] Pod default/scale-up-pod-6775c8dc87-lg6ff is unschedulable
I1129 14:26:07.716936   95247 orchestrator.go:111] Upcoming 3 nodes
I1129 14:26:07.716990   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z1 - max size reached
I1129 14:26:07.717004   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:26:07.717013   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z3 - max size reached
I1129 14:26:07.717295   95247 orchestrator.go:595] Pod default/scale-up-pod-6775c8dc87-rx27n can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:26:07.717325   95247 orchestrator.go:597] 4 other pods similar to scale-up-pod-6775c8dc87-rx27n can't be scheduled on shoot--i544000--ca-it-one-zone-z1
I1129 14:26:07.717360   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:26:07.717387   95247 orchestrator.go:169] No expansion options
I1129 14:26:07.717535   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:26:07.717583   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:07.717600   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:26:07.717784   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:26:07.717810   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:26:07.717840   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:26:07.717922   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:26:07.717972   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 1m14.830029917s
I1129 14:26:07.718061   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:26:07.718116   95247 static_autoscaler.go:647] Starting scale down
I1129 14:26:07.718158   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m14.830029917s
I1129 14:26:07.718248   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:09.890993   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicationController total 6 items received
I1129 14:26:17.996181   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineDeployment total 45 items received
I1129 14:26:18.293747   95247 static_autoscaler.go:306] Starting main loop
I1129 14:26:18.294027   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:18.294093   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:18.294134   95247 taints.go:442] Overriding status of node ip-10-180-142-148.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:26:18.295431   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:26:18.296232   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:18.296257   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:18.296286   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:18.296851   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:18.296876   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-26-210.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:26:18.296899   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:18.297429   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:18.297449   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:18.297506   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:18.298454   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:18.298585   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z1 finished successfully in 1m35.866213833s
I1129 14:26:18.298606   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z3 finished successfully in 1m37.06483875s
I1129 14:26:18.299146   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:26:18.299171   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:26:18.299226   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:26:18.299242   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:26:18.299253   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:26:18.299288   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:26:18.299319   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:26:18.299364   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:18.299387   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:26:18.299763   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:26:18.299793   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:26:18.299886   95247 eligibility.go:167] Node ip-10-180-26-210.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:18.299913   95247 klogx.go:87] Node ip-10-180-26-210.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:18.299999   95247 eligibility.go:167] Node ip-10-180-79-35.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:18.300012   95247 klogx.go:87] Node ip-10-180-79-35.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:18.300040   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:26:18.300100   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:26:18.300128   95247 cluster.go:156] Simulating node ip-10-180-26-210.eu-west-1.compute.internal removal
I1129 14:26:18.300170   95247 cluster.go:174] node ip-10-180-26-210.eu-west-1.compute.internal may be removed
I1129 14:26:18.300194   95247 cluster.go:156] Simulating node ip-10-180-79-35.eu-west-1.compute.internal removal
I1129 14:26:18.300232   95247 cluster.go:174] node ip-10-180-79-35.eu-west-1.compute.internal may be removed
I1129 14:26:18.300267   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 1m25.414370917s
I1129 14:26:18.300294   95247 nodes.go:84] ip-10-180-26-210.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:18.29369 +0530 IST m=+695.988246168 duration 0s
I1129 14:26:18.300308   95247 nodes.go:84] ip-10-180-79-35.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:18.29369 +0530 IST m=+695.988246168 duration 0s
I1129 14:26:18.300389   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:26:18.300429   95247 static_autoscaler.go:647] Starting scale down
I1129 14:26:18.300470   95247 nodes.go:126] ip-10-180-79-35.eu-west-1.compute.internal was unneeded for 0s
I1129 14:26:18.300493   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m25.414370917s
I1129 14:26:18.300510   95247 nodes.go:126] ip-10-180-26-210.eu-west-1.compute.internal was unneeded for 0s
I1129 14:26:18.300573   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:18.742302   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-26-210.eu-west-1.compute.internal
I1129 14:26:19.180574   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-79-35.eu-west-1.compute.internal
I1129 14:26:29.636154   95247 static_autoscaler.go:306] Starting main loop
I1129 14:26:29.636464   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:29.636540   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:29.637982   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:26:29.638921   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:29.638947   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:29.638986   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:29.639636   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:29.639656   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:29.639680   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:29.640266   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:29.640289   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-26-210.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:26:29.640314   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:29.641175   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:29.641272   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z2 finished successfully in 1m47.8110895s
I1129 14:26:29.641373   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:26:29.641395   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:26:29.641416   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:26:29.641427   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:26:29.641437   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:26:29.641471   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:26:29.641507   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:26:29.641542   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:29.641558   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:26:29.641956   95247 eligibility.go:167] Node ip-10-180-89-70.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:26:29.641986   95247 klogx.go:87] Node ip-10-180-89-70.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:26:29.642084   95247 eligibility.go:167] Node ip-10-180-26-210.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:29.642097   95247 klogx.go:87] Node ip-10-180-26-210.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:29.642182   95247 eligibility.go:167] Node ip-10-180-79-35.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:29.642195   95247 klogx.go:87] Node ip-10-180-79-35.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:29.642286   95247 eligibility.go:167] Node ip-10-180-142-148.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:29.642298   95247 klogx.go:87] Node ip-10-180-142-148.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:29.642323   95247 cluster.go:156] Simulating node ip-10-180-89-70.eu-west-1.compute.internal removal
I1129 14:26:29.642385   95247 cluster.go:174] node ip-10-180-89-70.eu-west-1.compute.internal may be removed
I1129 14:26:29.642416   95247 cluster.go:156] Simulating node ip-10-180-26-210.eu-west-1.compute.internal removal
I1129 14:26:29.642462   95247 cluster.go:174] node ip-10-180-26-210.eu-west-1.compute.internal may be removed
I1129 14:26:29.642490   95247 cluster.go:156] Simulating node ip-10-180-79-35.eu-west-1.compute.internal removal
I1129 14:26:29.642531   95247 cluster.go:174] node ip-10-180-79-35.eu-west-1.compute.internal may be removed
I1129 14:26:29.642555   95247 cluster.go:156] Simulating node ip-10-180-142-148.eu-west-1.compute.internal removal
I1129 14:26:29.642606   95247 cluster.go:174] node ip-10-180-142-148.eu-west-1.compute.internal may be removed
I1129 14:26:29.642642   95247 nodes.go:84] ip-10-180-89-70.eu-west-1.compute.internal is unneeded since 2024-11-29 14:24:52.88 +0530 IST m=+610.573875251 duration 1m36.756792167s
I1129 14:26:29.642674   95247 nodes.go:84] ip-10-180-26-210.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:18.29369 +0530 IST m=+695.988246168 duration 11.34242125s
I1129 14:26:29.642686   95247 nodes.go:84] ip-10-180-79-35.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:18.29369 +0530 IST m=+695.988246168 duration 11.34242125s
I1129 14:26:29.642695   95247 nodes.go:84] ip-10-180-142-148.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:29.636021 +0530 IST m=+707.330667418 duration 0s
I1129 14:26:29.642791   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:23:57.901056 +0530 IST m=+555.594493001 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:26:29.642845   95247 static_autoscaler.go:647] Starting scale down
I1129 14:26:29.642895   95247 nodes.go:126] ip-10-180-79-35.eu-west-1.compute.internal was unneeded for 11.34242125s
I1129 14:26:29.642928   95247 nodes.go:126] ip-10-180-142-148.eu-west-1.compute.internal was unneeded for 0s
I1129 14:26:29.642952   95247 nodes.go:126] ip-10-180-89-70.eu-west-1.compute.internal was unneeded for 1m36.756792167s
I1129 14:26:29.642975   95247 nodes.go:126] ip-10-180-26-210.eu-west-1.compute.internal was unneeded for 11.34242125s
I1129 14:26:29.643020   95247 klogx.go:87] Considering node ip-10-180-79-35.eu-west-1.compute.internal for standard scale down
I1129 14:26:29.643047   95247 klogx.go:87] Considering node ip-10-180-26-210.eu-west-1.compute.internal for standard scale down
I1129 14:26:30.328083   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-79-35.eu-west-1.compute.internal
I1129 14:26:30.328280   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-79-35.eu-west-1.compute.internal", UID:"4df15727-c688-42e3-b19b-8a876252a096", APIVersion:"v1", ResourceVersion:"14034", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:26:30.566645   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-26-210.eu-west-1.compute.internal
I1129 14:26:30.566726   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-79-35.eu-west-1.compute.internal"
I1129 14:26:30.567008   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-26-210.eu-west-1.compute.internal"
I1129 14:26:30.567221   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:26:30.567242   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:26:30.575343   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-26-210.eu-west-1.compute.internal", UID:"824be10e-59d2-4f7e-8ade-09d52c72be13", APIVersion:"v1", ResourceVersion:"13980", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:26:30.802325   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"13960", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' Scale-down: removing empty node "ip-10-180-79-35.eu-west-1.compute.internal"
I1129 14:26:31.026593   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"13960", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-26-210.eu-west-1.compute.internal"
I1129 14:26:35.568846   95247 drain.go:131] All pods removed from ip-10-180-26-210.eu-west-1.compute.internal
I1129 14:26:35.568846   95247 drain.go:131] All pods removed from ip-10-180-79-35.eu-west-1.compute.internal
I1129 14:26:35.568996   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-26-210.eu-west-1.compute.internal]
I1129 14:26:35.568996   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-79-35.eu-west-1.compute.internal]
I1129 14:26:36.739249   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z3-7bb4b-mv54m marked with priority 1 successfully
I1129 14:26:36.739318   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z3-7bb4b-mv54m:ip-10-180-26-210.eu-west-1.compute.internal]
I1129 14:26:37.795468   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z1-745f9-5wk65 marked with priority 1 successfully
I1129 14:26:37.795524   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z1-745f9-5wk65:ip-10-180-79-35.eu-west-1.compute.internal]
I1129 14:26:38.050631   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z3 size decreased to 0 
I1129 14:26:38.051133   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"14064", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-26-210.eu-west-1.compute.internal removed
I1129 14:26:38.571317   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z1 size decreased to 1 
I1129 14:26:38.571781   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"14064", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-79-35.eu-west-1.compute.internal removed
I1129 14:26:41.019377   95247 static_autoscaler.go:306] Starting main loop
I1129 14:26:41.019716   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:41.019821   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:41.021163   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:41.021192   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:41.021234   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:41.022209   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:26:41.022843   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:41.022866   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:41.022886   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:41.023540   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:41.023561   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:41.023581   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:41.024416   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:41.024610   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:26:41.024632   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:26:41.024691   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:26:41.024728   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:26:41.024742   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:26:41.024778   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:26:41.024810   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:26:41.024882   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:41.024904   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:26:41.024930   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:26:41.024969   95247 pre_filtering_processor.go:67] Skipping ip-10-180-26-210.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:26:41.024987   95247 pre_filtering_processor.go:67] Skipping ip-10-180-79-35.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:26:41.025121   95247 eligibility.go:167] Node ip-10-180-142-148.eu-west-1.compute.internal is underutilized: cpu requested (20.4688% of allocatable) is below the scale-down utilization threshold
I1129 14:26:41.025150   95247 klogx.go:87] Node ip-10-180-142-148.eu-west-1.compute.internal - cpu requested is 20.4688% of allocatable
I1129 14:26:41.025180   95247 cluster.go:156] Simulating node ip-10-180-142-148.eu-west-1.compute.internal removal
I1129 14:26:41.025255   95247 cluster.go:174] node ip-10-180-142-148.eu-west-1.compute.internal may be removed
I1129 14:26:41.025300   95247 nodes.go:84] ip-10-180-142-148.eu-west-1.compute.internal is unneeded since 2024-11-29 14:26:29.636021 +0530 IST m=+707.330667418 duration 11.383365625s
I1129 14:26:41.025411   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:26:29.636021 +0530 IST m=+707.330667418 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:26:41.025466   95247 static_autoscaler.go:647] Starting scale down
I1129 14:26:41.025520   95247 nodes.go:126] ip-10-180-142-148.eu-west-1.compute.internal was unneeded for 11.383365625s
I1129 14:26:41.025574   95247 klogx.go:87] Considering node ip-10-180-142-148.eu-west-1.compute.internal for standard scale down
I1129 14:26:41.477942   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-142-148.eu-west-1.compute.internal
I1129 14:26:41.478008   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-142-148.eu-west-1.compute.internal"
I1129 14:26:41.478278   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-142-148.eu-west-1.compute.internal", UID:"991d248f-deef-47da-b517-5774be2ac2f4", APIVersion:"v1", ResourceVersion:"13978", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:26:41.478750   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:26:41.703122   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"14064", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-142-148.eu-west-1.compute.internal"
I1129 14:26:45.906913   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:26:45.907094   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 134.209Âµs
I1129 14:26:46.479798   95247 drain.go:131] All pods removed from ip-10-180-142-148.eu-west-1.compute.internal
I1129 14:26:46.479954   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-142-148.eu-west-1.compute.internal]
I1129 14:26:47.549163   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z2-967d8-z7448 marked with priority 1 successfully
I1129 14:26:47.549228   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z2-967d8-z7448:ip-10-180-142-148.eu-west-1.compute.internal]
I1129 14:26:48.337986   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z2 size decreased to 0 
I1129 14:26:48.338594   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"14147", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-142-148.eu-west-1.compute.internal removed
I1129 14:26:48.885339   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Job total 5 items received
I1129 14:26:51.961061   95247 static_autoscaler.go:306] Starting main loop
I1129 14:26:51.961192   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:51.961233   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:26:51.961891   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:51.961910   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:51.961929   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:51.962534   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:51.962544   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:51.962554   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:51.962911   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:26:51.963183   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:26:51.963194   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:26:51.963268   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:26:51.963609   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:51.963719   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:26:51.963728   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:26:51.963736   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:26:51.963741   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:26:51.963745   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:26:51.963759   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:26:51.963770   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:26:51.963786   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:26:51.963792   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:26:51.963802   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:26:51.963810   95247 pre_filtering_processor.go:67] Skipping ip-10-180-26-210.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:26:51.963817   95247 pre_filtering_processor.go:67] Skipping ip-10-180-79-35.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:26:51.963825   95247 pre_filtering_processor.go:67] Skipping ip-10-180-142-148.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:26:51.963855   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:02.414039   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:02.414370   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:02.414439   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:02.415893   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:02.416756   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:02.416787   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-26-210.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:27:02.416832   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:02.417525   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:02.417549   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:02.417568   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:02.418130   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:02.418149   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:02.418167   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:02.418846   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:02.419149   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:02.419216   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:27:02.419246   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:27:02.419258   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:02.419268   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:27:02.419305   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:27:02.419337   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:27:02.419386   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:02.419402   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:27:02.419429   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:02.419456   95247 pre_filtering_processor.go:67] Skipping ip-10-180-26-210.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:27:02.419477   95247 pre_filtering_processor.go:67] Skipping ip-10-180-79-35.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:02.419499   95247 pre_filtering_processor.go:67] Skipping ip-10-180-142-148.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:27:02.419583   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:13.055131   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:13.055460   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:13.055563   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:13.056747   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:13.056777   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:13.056820   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:13.057648   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:13.058244   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:13.058264   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:13.058288   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:13.058907   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:13.058928   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-142-148.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:13.058954   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:13.059663   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:13.059705   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:13.059717   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:13.059736   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:27:13.059757   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:13.059767   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:13.059790   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:27:13.059862   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:27:13.059884   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:13.059908   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:13.059922   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:27:13.059938   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:13.059948   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:13.059957   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:27:13.060011   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:13.060040   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:27:13.060061   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:27:13.060072   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:13.060080   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:27:13.060114   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:27:13.060153   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:27:13.060193   95247 pre_filtering_processor.go:67] Skipping ip-10-180-142-148.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:27:13.060214   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:13.060228   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:27:13.060249   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:13.060327   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:24:40.432843 +0530 IST m=+598.126619335 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:21.979092   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineSet total 34 items received
I1129 14:27:23.603228   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:23.603423   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:23.603493   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:23.604119   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:23.604695   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:23.604712   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:23.604726   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:23.605170   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:23.605182   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:23.605192   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:23.605503   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:23.605512   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:23.605522   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:23.605826   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:23.605856   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:23.605863   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:23.605872   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:27:23.605880   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-06a4d5b26d1174ac6"
I1129 14:27:23.605883   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-06a4d5b26d1174ac6, it's either been removed or it's not managed by this controller
W1129 14:27:23.605888   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-06a4d5b26d1174ac6
I1129 14:27:23.605896   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:23.605900   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:23.605905   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:27:23.605948   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:27:23.605959   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:23.605964   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:23.605971   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:27:23.605976   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-06a4d5b26d1174ac6"
I1129 14:27:23.605981   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-06a4d5b26d1174ac6, it's either been removed or it's not managed by this controller
W1129 14:27:23.605984   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-06a4d5b26d1174ac6, skipping
I1129 14:27:23.605989   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:23.605993   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:23.605997   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:27:23.606036   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:23.606208   95247 klogx.go:87] failed to find place for default/small-scale-up-pod-b665d566-fgjpn: cannot put pod small-scale-up-pod-b665d566-fgjpn on any node
I1129 14:27:23.606229   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:27:23.606241   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:27:23.606248   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:23.606254   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:27:23.606266   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn is unschedulable
I1129 14:27:23.606289   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:27:23.606491   95247 orchestrator.go:595] Pod default/small-scale-up-pod-b665d566-fgjpn can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:27:23.606726   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:27:23.606761   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-6506057911320840188 and template-node-for-shoot--i544000--ca-it-one-zone-z1-7917828123869948526 are not similar, ephemeral-storage does not match
I1129 14:27:23.607161   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-5593056053444351216 and template-node-for-shoot--i544000--ca-it-one-zone-z1-7917828123869948526 are not similar, ephemeral-storage does not match
I1129 14:27:23.607568   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z3-7527326965499070075 and template-node-for-shoot--i544000--ca-it-one-zone-z1-7917828123869948526 are not similar, ephemeral-storage does not match
I1129 14:27:23.607919   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z1 would waste 75.00% CPU, 99.35% Memory, 87.18% Blended
I1129 14:27:23.607939   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 75.00% CPU, 99.35% Memory, 87.18% Blended
I1129 14:27:23.607945   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z3 would waste 75.00% CPU, 99.35% Memory, 87.18% Blended
I1129 14:27:23.607956   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z1
I1129 14:27:23.607964   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-three-zones-z1
I1129 14:27:23.607985   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z1-6506057911320840188 and template-node-for-shoot--i544000--ca-it-one-zone-z1-7917828123869948526 are not similar, ephemeral-storage does not match
I1129 14:27:23.608029   95247 orchestrator.go:697] Found 2 similar node groups: [shoot--i544000--ca-it-three-zones-z2 shoot--i544000--ca-it-three-zones-z3]
I1129 14:27:23.608045   95247 orchestrator.go:713] Splitting scale-up between 3 similar node groups: {shoot--i544000--ca-it-three-zones-z1, shoot--i544000--ca-it-three-zones-z2, shoot--i544000--ca-it-three-zones-z3}
I1129 14:27:23.608067   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)}]
I1129 14:27:23.608085   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1
I1129 14:27:23.608121   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z2 by 1
I1129 14:27:24.398960   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W1129 14:27:24.399063   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z2
I1129 14:27:24.399338   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"small-scale-up-pod-b665d566-fgjpn", UID:"8fcd5212-85ab-452d-82bf-d95ba1408e23", APIVersion:"v1", ResourceVersion:"14466", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)}]
I1129 14:27:28.883647   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StorageClass total 7 items received
I1129 14:27:34.848920   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:34.849195   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:34.849272   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:34.850157   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:34.850187   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:34.850228   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:34.851141   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:34.851766   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:34.851788   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:34.851810   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:34.852380   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:34.852402   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:34.852424   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:27:34.853017   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z2
I1129 14:27:34.853092   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:34.853136   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:34.853149   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:34.853167   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:27:34.853184   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-06a4d5b26d1174ac6"
I1129 14:27:34.853194   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-06a4d5b26d1174ac6, it's either been removed or it's not managed by this controller
W1129 14:27:34.853207   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-06a4d5b26d1174ac6
I1129 14:27:34.853222   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:34.853231   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:34.853243   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:27:34.853324   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:27:34.853352   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-06a4d5b26d1174ac6"
I1129 14:27:34.853365   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-06a4d5b26d1174ac6, it's either been removed or it's not managed by this controller
W1129 14:27:34.853378   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-06a4d5b26d1174ac6, skipping
I1129 14:27:34.853392   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:34.853402   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:34.853413   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:27:34.853427   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:34.853436   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:34.853446   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:27:34.853877   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:34.854155   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-2155469613014403610-upcoming-0
I1129 14:27:34.854198   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:27:34.854222   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:27:34.854236   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:34.854245   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:27:34.854279   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:27:34.854313   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:27:34.854362   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:34.854379   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:27:34.854410   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:34.854497   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:45.307305   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:45.307603   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:45.307668   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:45.308578   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:45.308621   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:45.308663   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:45.309481   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:45.309504   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:45.309525   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:45.310369   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:45.311041   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:45.311064   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:45.311084   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:45.311794   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:45.311846   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:45.311865   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:45.311884   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:27:45.311922   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:45.311932   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:45.311945   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:27:45.312021   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:27:45.312061   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:45.312075   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:45.312088   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:27:45.312103   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:45.312113   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:45.312122   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:27:45.312647   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:45.312872   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-2447441055861351317-upcoming-0
I1129 14:27:45.312916   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:27:45.312941   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:27:45.312954   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:45.312963   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:27:45.312996   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:27:45.313029   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:27:45.313078   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:45.313096   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:27:45.313123   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:45.313203   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:55.770247   95247 static_autoscaler.go:306] Starting main loop
I1129 14:27:55.770544   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:55.770609   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:27:55.771515   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:27:55.772294   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:55.772322   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:55.772346   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:55.772939   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:55.772958   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:55.772977   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:55.773665   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:27:55.773687   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:27:55.773708   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:27:55.774506   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:55.774570   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:55.774587   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:55.774605   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:27:55.774621   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:55.774633   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:55.774644   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:27:55.774765   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:27:55.774790   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:27:55.774803   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:27:55.774818   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:27:55.774857   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:27:55.774880   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:27:55.774891   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:27:55.775356   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:27:55.775604   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-8283990302891663397-upcoming-0
I1129 14:27:55.775655   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:27:55.775678   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:27:55.775692   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:27:55.775701   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:27:55.775740   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:27:55.775774   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:27:55.775819   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:27:55.775837   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:27:55.775864   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:27:55.775945   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:27:57.881472   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIStorageCapacity total 7 items received
I1129 14:27:58.963510   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 178 items received
I1129 14:28:06.326759   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:06.326927   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:06.326978   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:06.327454   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:06.327480   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:06.327509   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:06.328108   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:06.328580   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:06.328600   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:06.328619   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:06.329139   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:06.329159   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:06.329180   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:06.329795   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:06.329819   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:06.329833   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:06.329848   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:28:06.329884   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:06.329897   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:06.329910   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:28:06.329969   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:28:06.329994   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:06.330006   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:06.330025   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:28:06.330051   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:06.330061   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:06.330071   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:28:06.330426   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:06.330568   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7037016234923956165-upcoming-0
I1129 14:28:06.330600   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:28:06.330615   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:28:06.330625   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:06.330634   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:06.330665   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:06.330699   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:06.330729   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:06.330751   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:06.330763   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:06.330821   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:28:09.888037   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 179 items received
I1129 14:28:10.884482   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolume total 7 items received
I1129 14:28:12.878448   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicaSet total 30 items received
I1129 14:28:16.849945   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:16.850243   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:16.850315   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:16.851074   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:16.851103   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:16.851170   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:16.851992   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:16.852014   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:16.852036   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:16.852603   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:16.852625   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:16.852645   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:16.853187   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:16.853847   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:16.853895   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:16.853909   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:16.853928   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:28:16.853943   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:16.853953   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:16.853964   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:28:16.854059   95247 static_autoscaler.go:439] 3 unregistered nodes present
I1129 14:28:16.854097   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:16.854109   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:16.854123   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:28:16.854136   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:16.854147   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:16.854157   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:28:16.854574   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:16.854830   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-3099444819122417539-upcoming-0
I1129 14:28:16.854876   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:28:16.854899   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:28:16.854913   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:16.854923   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:16.854956   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:16.854996   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:16.855041   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:16.855058   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:16.855085   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:16.855165   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:28:27.396527   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:27.396833   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:27.396898   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:27.397840   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:27.398638   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:27.398667   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:27.398693   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:27.399276   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:27.399298   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:27.399320   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:27.399966   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:27.399989   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:27.400008   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:27.400758   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:27.400838   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:27.400852   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:27.400871   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:28:27.400887   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:27.400896   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:27.400909   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:28:27.401043   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:28:27.401093   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:27.401108   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:27.401133   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:28:27.401150   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:27.401160   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:27.401232   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:28:27.401843   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:27.402114   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-8757045497714213919-upcoming-0
I1129 14:28:27.402143   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:28:27.402167   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:28:27.402181   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:27.402189   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:27.402223   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:27.402254   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:27.402301   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:27.402347   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:27.402381   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:27.402459   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:28:31.889436   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Pod total 551 items received
I1129 14:28:34.885539   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StatefulSet total 9 items received
I1129 14:28:37.858655   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:37.858888   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:37.858946   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:37.859879   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:37.860676   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:37.860703   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:37.860731   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:37.861373   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:37.861394   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:37.861415   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:37.861910   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:37.861936   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-150-199.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:28:37.861955   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:37.862627   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:37.862690   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:37.862703   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:37.862721   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1a/i-079a7833987aa735b
I1129 14:28:37.862741   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:37.862752   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:37.862765   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-0395b870c86858315
I1129 14:28:37.862835   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:28:37.862856   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1a/i-079a7833987aa735b"
I1129 14:28:37.862867   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1a/i-079a7833987aa735b, it's either been removed or it's not managed by this controller
W1129 14:28:37.862880   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1a/i-079a7833987aa735b, skipping
I1129 14:28:37.862895   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-0395b870c86858315"
I1129 14:28:37.862905   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-0395b870c86858315, it's either been removed or it's not managed by this controller
W1129 14:28:37.862914   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-0395b870c86858315, skipping
I1129 14:28:37.863328   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:37.863578   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7920949251746236423-upcoming-0
I1129 14:28:37.863611   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:28:37.863634   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:28:37.863648   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:37.863658   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:37.863693   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:37.863729   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:37.863770   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:37.863786   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:37.863819   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:37.863899   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:28:45.907325   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:28:45.907619   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 210Âµs
I1129 14:28:48.316396   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:48.316830   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:48.316890   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:48.317912   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:48.317952   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:48.318006   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:48.318669   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:48.318684   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:48.318699   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:48.319236   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:48.319248   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:48.319262   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:48.319794   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:48.320388   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:48.320851   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:48.321047   95247 klogx.go:87] Pod default/small-scale-up-pod-b665d566-fgjpn can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-5889769181053115073-upcoming-0
I1129 14:28:48.321080   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:28:48.321098   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:28:48.321109   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:48.321117   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:48.321143   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:48.321166   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:48.321202   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:48.321217   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:48.321237   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:48.321304   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:28:56.883283   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolumeClaim total 9 items received
I1129 14:28:58.982726   95247 static_autoscaler.go:306] Starting main loop
I1129 14:28:58.983007   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:58.983088   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:28:58.983145   95247 taints.go:442] Overriding status of node ip-10-180-150-199.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:28:58.984220   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:58.984247   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:58.984287   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:58.985078   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:28:58.985722   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:58.985744   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:58.985764   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:58.986381   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:28:58.986403   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:28:58.986424   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:28:58.987090   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:58.987588   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:28:58.987611   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:28:58.987633   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:28:58.987644   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:28:58.987654   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:28:58.987686   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:28:58.987721   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:28:58.987762   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:28:58.987785   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:28:58.987797   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:28:58.987878   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:29:03.883053   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PodDisruptionBudget total 16 items received
I1129 14:29:09.562072   95247 static_autoscaler.go:306] Starting main loop
I1129 14:29:09.562253   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:09.562292   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:09.562808   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:09.562826   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:09.562850   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:09.563312   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:29:09.563679   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:09.563695   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:09.563708   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:09.564072   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:09.564088   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:09.564102   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:09.564526   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:09.564559   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z2 finished successfully in 1m45.164068041s
I1129 14:29:09.564604   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:29:09.564615   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:29:09.564624   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:29:09.564630   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:29:09.564636   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:29:09.564654   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:29:09.564685   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:29:09.564741   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:09.564754   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:29:09.564768   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:29:09.564854   95247 eligibility.go:167] Node ip-10-180-150-199.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:29:09.564869   95247 klogx.go:87] Node ip-10-180-150-199.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:29:09.564883   95247 cluster.go:156] Simulating node ip-10-180-150-199.eu-west-1.compute.internal removal
I1129 14:29:09.564921   95247 cluster.go:174] node ip-10-180-150-199.eu-west-1.compute.internal may be removed
I1129 14:29:09.564939   95247 nodes.go:84] ip-10-180-150-199.eu-west-1.compute.internal is unneeded since 2024-11-29 14:29:09.562034 +0530 IST m=+867.257955251 duration 0s
I1129 14:29:09.564983   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:29:09.565009   95247 static_autoscaler.go:647] Starting scale down
I1129 14:29:09.565030   95247 nodes.go:126] ip-10-180-150-199.eu-west-1.compute.internal was unneeded for 0s
I1129 14:29:09.565072   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:09.565108   95247 taints.go:317] Releasing taint {Key:DeletionCandidateOfClusterAutoscaler Value:1732870492 Effect:PreferNoSchedule TimeAdded:<nil>} on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:29:09.805110   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Deployment total 154 items received
I1129 14:29:10.008556   95247 taints.go:352] Successfully released DeletionCandidateOfClusterAutoscaler on node ip-10-180-89-70.eu-west-1.compute.internal
I1129 14:29:10.238217   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-150-199.eu-west-1.compute.internal
I1129 14:29:20.694850   95247 static_autoscaler.go:306] Starting main loop
I1129 14:29:20.695166   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:20.695232   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:20.696221   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:20.696251   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:20.696291   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:20.697075   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:29:20.697694   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:20.697715   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:20.697737   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:20.698250   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:20.698267   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:20.698285   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:20.698922   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:20.699026   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:29:20.699048   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:29:20.699067   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:29:20.699079   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:29:20.699088   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:29:20.699124   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:29:20.699155   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:29:20.699197   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:29:20.699232   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:20.699247   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:29:20.699390   95247 eligibility.go:167] Node ip-10-180-150-199.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:29:20.699421   95247 klogx.go:87] Node ip-10-180-150-199.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:29:20.699451   95247 cluster.go:156] Simulating node ip-10-180-150-199.eu-west-1.compute.internal removal
I1129 14:29:20.699531   95247 cluster.go:174] node ip-10-180-150-199.eu-west-1.compute.internal may be removed
I1129 14:29:20.699566   95247 nodes.go:84] ip-10-180-150-199.eu-west-1.compute.internal is unneeded since 2024-11-29 14:29:09.562034 +0530 IST m=+867.257955251 duration 11.132829875s
I1129 14:29:20.699650   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:26:41.019296 +0530 IST m=+718.714033043 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:29:20.699703   95247 static_autoscaler.go:647] Starting scale down
I1129 14:29:20.699751   95247 nodes.go:126] ip-10-180-150-199.eu-west-1.compute.internal was unneeded for 11.132829875s
I1129 14:29:20.699807   95247 klogx.go:87] Considering node ip-10-180-150-199.eu-west-1.compute.internal for standard scale down
I1129 14:29:21.146273   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-150-199.eu-west-1.compute.internal
I1129 14:29:21.146365   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-150-199.eu-west-1.compute.internal"
I1129 14:29:21.146452   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-150-199.eu-west-1.compute.internal", UID:"d0d8d767-6257-4780-b578-c0c5fa77e1a4", APIVersion:"v1", ResourceVersion:"15604", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:29:21.146555   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:29:21.375660   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"15607", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-150-199.eu-west-1.compute.internal"
I1129 14:29:26.147912   95247 drain.go:131] All pods removed from ip-10-180-150-199.eu-west-1.compute.internal
I1129 14:29:26.148008   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-150-199.eu-west-1.compute.internal]
I1129 14:29:27.198352   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z2-967d8-kjz4q marked with priority 1 successfully
I1129 14:29:27.198388   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z2-967d8-kjz4q:ip-10-180-150-199.eu-west-1.compute.internal]
I1129 14:29:27.727644   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z2 size decreased to 0 
I1129 14:29:27.728010   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"15685", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-150-199.eu-west-1.compute.internal removed
I1129 14:29:31.604348   95247 static_autoscaler.go:306] Starting main loop
I1129 14:29:31.604509   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:31.604639   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:31.605274   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:29:31.605900   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:31.605913   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:31.605923   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:31.606406   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:31.606418   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:31.606428   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:31.606672   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:31.606682   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:31.606690   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:31.607000   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:31.607072   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:29:31.607082   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:29:31.607090   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:29:31.607095   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:29:31.607098   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:29:31.607112   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:29:31.607123   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:29:31.607137   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:31.607145   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:29:31.607166   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:29:31.607178   95247 pre_filtering_processor.go:67] Skipping ip-10-180-150-199.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:29:31.607225   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:29:38.879201   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Namespace total 9 items received
I1129 14:29:42.059264   95247 static_autoscaler.go:306] Starting main loop
I1129 14:29:42.059582   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:42.059626   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:42.060218   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:29:42.060637   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:42.060648   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:42.060660   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:42.061021   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:42.061029   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:42.061042   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:42.061349   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:42.061358   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:42.061365   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:42.061650   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:42.061715   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:29:42.061727   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:29:42.061738   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:29:42.061743   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:29:42.061747   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:29:42.061760   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:29:42.061773   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:29:42.061789   95247 pre_filtering_processor.go:67] Skipping ip-10-180-150-199.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:29:42.061798   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:42.061803   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:29:42.061814   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:29:42.061857   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:29:52.516802   95247 static_autoscaler.go:306] Starting main loop
I1129 14:29:52.516981   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:52.517023   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:29:52.517776   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:29:52.518345   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:52.518358   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:52.518389   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:52.519185   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:52.519211   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:29:52.519233   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:52.519822   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:29:52.519850   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-150-199.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925032Ki
I1129 14:29:52.519872   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:29:52.520513   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:52.520677   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:29:52.520700   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:29:52.520720   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:29:52.520732   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:29:52.520741   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:29:52.520775   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:29:52.520806   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:29:52.520834   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:29:52.520854   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:29:52.520876   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:29:52.520901   95247 pre_filtering_processor.go:67] Skipping ip-10-180-150-199.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:29:52.520977   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:27:23.603082 +0530 IST m=+761.298158043 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:29:59.897714   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.DaemonSet total 175 items received
I1129 14:30:02.973353   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:02.973710   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:02.973815   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:02.974458   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:02.974495   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:02.974535   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:02.975405   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:02.976067   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:02.976107   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:02.976137   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:02.976872   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:02.976897   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:02.976917   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:02.977535   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:02.977577   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-07ac5e6f0d3f02abe"
I1129 14:30:02.977590   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, it's either been removed or it's not managed by this controller
W1129 14:30:02.977606   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-07ac5e6f0d3f02abe
I1129 14:30:02.977672   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:02.977693   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-07ac5e6f0d3f02abe"
I1129 14:30:02.977704   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, it's either been removed or it's not managed by this controller
W1129 14:30:02.977717   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, skipping
I1129 14:30:02.977759   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:02.978128   95247 klogx.go:87] failed to find place for default/volume-pod-54d4c76cb8-9bqmh: cannot put pod volume-pod-54d4c76cb8-9bqmh on any node
I1129 14:30:02.978149   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:30:02.978165   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:30:02.978175   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:02.978184   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:30:02.978201   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh is unschedulable
I1129 14:30:02.978239   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:30:02.978765   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-one-zone-z1-3115154108680838142" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-one-zone-z1-3115154108680838142\" not found"
I1129 14:30:02.978829   95247 binder.go:892] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i544000--ca-it-2a596454-0631-470b-b1c7-ab8d3adf4d01" node="template-node-for-shoot--i544000--ca-it-one-zone-z1-3115154108680838142" pod="default/volume-pod-54d4c76cb8-9bqmh" err="no matching NodeSelectorTerms"
I1129 14:30:02.978876   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I1129 14:30:02.979061   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z1-2994163229916888586" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z1-2994163229916888586\" not found"
I1129 14:30:02.979107   95247 binder.go:892] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i544000--ca-it-2a596454-0631-470b-b1c7-ab8d3adf4d01" node="template-node-for-shoot--i544000--ca-it-three-zones-z1-2994163229916888586" pod="default/volume-pod-54d4c76cb8-9bqmh" err="no matching NodeSelectorTerms"
I1129 14:30:02.979129   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-three-zones-z1, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I1129 14:30:02.979311   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552\" not found"
I1129 14:30:02.979350   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552"
I1129 14:30:02.979566   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z3-5071578314079760319" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z3-5071578314079760319\" not found"
I1129 14:30:02.979601   95247 binder.go:892] "PersistentVolume and node mismatch for pod" logger="Filter.VolumeBinding" PV="pv-shoot--i544000--ca-it-2a596454-0631-470b-b1c7-ab8d3adf4d01" node="template-node-for-shoot--i544000--ca-it-three-zones-z3-5071578314079760319" pod="default/volume-pod-54d4c76cb8-9bqmh" err="no matching NodeSelectorTerms"
I1129 14:30:02.979623   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-three-zones-z3, predicate checking error: node(s) had volume node affinity conflict; predicateName=VolumeBinding; reasons: node(s) had volume node affinity conflict; debugInfo=
I1129 14:30:02.979664   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:30:02.979674   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z1
I1129 14:30:02.979730   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3115154108680838142 are not similar, ephemeral-storage does not match
I1129 14:30:02.980427   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552-e-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552-e-0\" not found"
I1129 14:30:02.980475   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552-e-0"
I1129 14:30:02.980528   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z3
I1129 14:30:02.980548   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-three-zones-z2 would waste 50.00% CPU, 99.35% Memory, 74.68% Blended
I1129 14:30:02.980653   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-three-zones-z2
I1129 14:30:02.980718   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-three-zones-z2
I1129 14:30:02.980850   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-three-zones-z2-8822171391943265552 and template-node-for-shoot--i544000--ca-it-one-zone-z1-3115154108680838142 are not similar, ephemeral-storage does not match
I1129 14:30:02.980873   95247 orchestrator.go:700] No similar node groups found
I1129 14:30:02.980910   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)}]
I1129 14:30:02.980938   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1
I1129 14:30:02.980992   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-three-zones-z2 by 1
I1129 14:30:02.981312   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"15927", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-three-zones-z2 size to 1 instead of 0 (max: 1)
I1129 14:30:03.516111   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W1129 14:30:03.516226   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z2
I1129 14:30:03.516388   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"15927", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-three-zones-z2 size set to 1 instead of 0 (max: 1)
I1129 14:30:03.744148   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"volume-pod-54d4c76cb8-9bqmh", UID:"adb681da-7bdc-497e-85aa-017d32a43e1b", APIVersion:"v1", ResourceVersion:"16013", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-three-zones-z2 0->1 (max: 1)}]
I1129 14:30:13.967339   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:13.967700   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:13.967771   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:13.968397   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:13.969022   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:13.969035   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:13.969060   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:13.969503   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:13.969514   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:13.969528   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:13.969933   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:13.969945   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:13.969959   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:30:13.970288   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-three-zones-z2
I1129 14:30:13.970344   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:13.970375   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-07ac5e6f0d3f02abe"
I1129 14:30:13.970382   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, it's either been removed or it's not managed by this controller
W1129 14:30:13.970390   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1b/i-07ac5e6f0d3f02abe
I1129 14:30:13.970438   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:13.970453   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1b/i-07ac5e6f0d3f02abe"
I1129 14:30:13.970461   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, it's either been removed or it's not managed by this controller
W1129 14:30:13.970468   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1b/i-07ac5e6f0d3f02abe, skipping
I1129 14:30:13.970838   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:13.971089   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8277778822778476934-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-8277778822778476934-upcoming-0\" not found"
I1129 14:30:13.971150   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8277778822778476934-upcoming-0"
I1129 14:30:13.971173   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-8277778822778476934-upcoming-0
I1129 14:30:13.971193   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:30:13.971208   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:30:13.971216   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:13.971221   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:30:13.971237   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:30:13.971251   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:30:13.971288   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:13.971298   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:30:13.971313   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:30:13.971372   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:30:14.885537   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSINode total 30 items received
I1129 14:30:24.423008   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:24.423206   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:24.423264   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:24.424170   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:24.424200   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:24.424253   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:24.425197   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:24.425222   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:24.425243   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:24.425857   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:24.425877   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:24.425916   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:24.426537   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:24.427255   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:24.427375   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:24.428015   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:24.428338   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-7379047494423122228-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-7379047494423122228-upcoming-0\" not found"
I1129 14:30:24.428418   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-7379047494423122228-upcoming-0"
I1129 14:30:24.428480   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7379047494423122228-upcoming-0
I1129 14:30:24.428513   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:30:24.428536   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:30:24.428550   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:24.428559   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:30:24.428593   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:30:24.428625   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:30:24.428699   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:24.428716   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:30:24.428759   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:30:24.428842   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:30:34.887144   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:34.887379   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:34.887462   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:34.888288   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:34.889317   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:34.889354   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:34.889405   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:34.890130   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:34.890153   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:34.890173   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:34.890773   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:34.890793   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:34.890811   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:34.891605   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:34.891735   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:34.892295   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:34.892619   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-7076793338570988010-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-7076793338570988010-upcoming-0\" not found"
I1129 14:30:34.892700   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-7076793338570988010-upcoming-0"
I1129 14:30:34.892732   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-7076793338570988010-upcoming-0
I1129 14:30:34.892761   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:30:34.892787   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:30:34.892801   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:34.892810   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:30:34.892844   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:30:34.892875   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:30:34.892913   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:34.892930   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:30:34.892955   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:30:34.893033   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:30:45.343124   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:45.343304   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:45.343350   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:45.343932   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:45.344728   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:45.344748   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:45.344766   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:45.345462   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:45.345478   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:45.345491   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:45.346167   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:45.346179   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:45.346189   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:45.346902   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:45.346994   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:45.347373   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:45.347653   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8007992648000279223-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-8007992648000279223-upcoming-0\" not found"
I1129 14:30:45.347716   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-8007992648000279223-upcoming-0"
I1129 14:30:45.347750   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-8007992648000279223-upcoming-0
I1129 14:30:45.347769   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:30:45.347782   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:30:45.347792   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:45.347797   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:30:45.347824   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:30:45.347841   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:30:45.347877   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:30:45.347893   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:45.347900   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:30:45.347951   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:30:45.907828   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:30:45.908068   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 193.791Âµs
I1129 14:30:55.799550   95247 static_autoscaler.go:306] Starting main loop
I1129 14:30:55.799837   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:55.799924   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:30:55.800845   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:55.800882   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:55.800925   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:55.801959   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:30:55.802785   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:55.802808   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:55.802829   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:55.803509   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:30:55.803530   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:30:55.803550   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:30:55.804343   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:55.804488   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:30:55.805115   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:30:55.805449   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-6133242009268989097-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-6133242009268989097-upcoming-0\" not found"
I1129 14:30:55.805522   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-6133242009268989097-upcoming-0"
I1129 14:30:55.805561   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-6133242009268989097-upcoming-0
I1129 14:30:55.805605   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:30:55.805628   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:30:55.805641   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:30:55.805651   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:30:55.805684   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:30:55.805720   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:30:55.805770   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:30:55.805787   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:30:55.805812   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:30:55.805896   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:06.261306   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:06.261707   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:06.261802   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:06.262661   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:06.263542   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:06.263565   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:06.263583   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:06.264513   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:06.264545   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:06.264562   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:06.265256   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:06.265272   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:06.265285   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:06.265860   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:06.265951   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:31:06.266268   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:06.266520   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-5411175242876453012-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-5411175242876453012-upcoming-0\" not found"
I1129 14:31:06.266577   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-5411175242876453012-upcoming-0"
I1129 14:31:06.266601   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-5411175242876453012-upcoming-0
I1129 14:31:06.266620   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:31:06.266636   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:31:06.266648   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:06.266653   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:31:06.266673   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:31:06.266692   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:06.266723   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:06.266734   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:06.266752   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:06.266814   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:16.954694   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:16.954923   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:16.955019   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:16.955835   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:16.956543   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:16.956561   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:16.956585   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:16.957133   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:16.957147   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:16.957156   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:16.957615   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:16.957627   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-146-219.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7839020Ki
I1129 14:31:16.957638   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:16.958229   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:16.958689   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:16.958944   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-4008302762130237578-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-4008302762130237578-upcoming-0\" not found"
I1129 14:31:16.959018   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-4008302762130237578-upcoming-0"
I1129 14:31:16.959039   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-4008302762130237578-upcoming-0
I1129 14:31:16.959054   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:31:16.959066   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:31:16.959074   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:16.959081   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:31:16.959097   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:31:16.959110   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:16.959134   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:16.959143   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:16.959196   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:16.959248   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:26.259711   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineDeployment total 33 items received
I1129 14:31:27.411378   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:27.411524   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:27.411565   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:27.412127   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:27.412176   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:27.412210   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:27.412652   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:27.412666   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:27.412676   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:27.413003   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:27.413608   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:27.413620   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:27.413630   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:27.414079   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:27.414403   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:27.414559   95247 binder.go:872] "Could not get a CSINode object for the node" logger="Filter.VolumeBinding" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-4449613748445533927-upcoming-0" err="csinode.storage.k8s.io \"template-node-for-shoot--i544000--ca-it-three-zones-z2-4449613748445533927-upcoming-0\" not found"
I1129 14:31:27.414585   95247 binder.go:898] "All bound volumes for pod match with node" logger="Filter.VolumeBinding" pod="default/volume-pod-54d4c76cb8-9bqmh" node="template-node-for-shoot--i544000--ca-it-three-zones-z2-4449613748445533927-upcoming-0"
I1129 14:31:27.414600   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh can be moved to template-node-for-shoot--i544000--ca-it-three-zones-z2-4449613748445533927-upcoming-0
I1129 14:31:27.414611   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:31:27.414619   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:31:27.414625   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:27.414629   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:31:27.414642   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:31:27.414654   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:27.414670   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:27.414677   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:27.414687   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:27.414722   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:36.106926   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Service total 6 items received
I1129 14:31:36.110519   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicationController total 2 items received
I1129 14:31:37.880391   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:37.880513   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:37.880563   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:37.880965   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:37.880977   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:37.880999   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:37.881388   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:37.881398   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:37.881406   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:37.881673   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:37.881930   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:37.881939   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:37.881947   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:37.882254   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:37.882496   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:37.882535   95247 klogx.go:87] failed to find place for default/volume-pod-54d4c76cb8-9bqmh: error running pre filter plugins for pod volume-pod-54d4c76cb8-9bqmh; persistentvolumeclaim "myclaim" not found
I1129 14:31:37.882544   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:31:37.882552   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:31:37.882556   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:37.882560   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:31:37.882567   95247 klogx.go:87] Pod default/volume-pod-54d4c76cb8-9bqmh is unschedulable
I1129 14:31:37.882583   95247 orchestrator.go:111] Upcoming 1 nodes
I1129 14:31:37.882608   95247 orchestrator.go:415] Skipping node group shoot--i544000--ca-it-three-zones-z2 - max size reached
I1129 14:31:37.882678   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: persistentvolumeclaim "myclaim" not found; predicateName=; reasons: persistentvolumeclaim "myclaim" not found; debugInfo=
I1129 14:31:37.882727   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-three-zones-z1, predicate checking error: persistentvolumeclaim "myclaim" not found; predicateName=; reasons: persistentvolumeclaim "myclaim" not found; debugInfo=
I1129 14:31:37.882777   95247 orchestrator.go:595] Pod default/volume-pod-54d4c76cb8-9bqmh can't be scheduled on shoot--i544000--ca-it-three-zones-z3, predicate checking error: persistentvolumeclaim "myclaim" not found; predicateName=; reasons: persistentvolumeclaim "myclaim" not found; debugInfo=
I1129 14:31:37.882786   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:31:37.882790   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z1
I1129 14:31:37.882794   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z3
I1129 14:31:37.882800   95247 orchestrator.go:169] No expansion options
I1129 14:31:37.882835   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:37.882849   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:37.882856   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:37.882865   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:37.882876   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"volume-pod-54d4c76cb8-9bqmh", UID:"adb681da-7bdc-497e-85aa-017d32a43e1b", APIVersion:"v1", ResourceVersion:"16013", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 3 persistentvolumeclaim "myclaim" not found, 1 max node group size reached
I1129 14:31:37.882897   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:48.361759   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:48.361959   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:48.362028   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:48.362061   95247 taints.go:442] Overriding status of node ip-10-180-146-219.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:31:48.362962   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:48.363767   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:48.363787   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:48.363821   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:48.364420   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:48.364438   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:48.364466   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:48.365007   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:48.365031   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:48.365051   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:48.365821   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:48.366827   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:48.366862   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:31:48.366885   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:31:48.366895   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:48.366902   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:31:48.366982   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:31:48.367012   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:48.367097   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:48.367147   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:48.367159   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:48.367266   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:31:58.820936   95247 static_autoscaler.go:306] Starting main loop
I1129 14:31:58.821182   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:58.821338   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:31:58.822119   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:31:58.822763   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:58.822778   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:58.822795   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:58.823253   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:58.823266   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:58.823283   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:58.823759   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:31:58.823775   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:31:58.823788   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:31:58.824621   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:58.824685   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-three-zones-z2 finished successfully in 1m55.305844458s
I1129 14:31:58.824765   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:31:58.824781   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:31:58.824796   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:31:58.824803   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:31:58.824809   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:31:58.824830   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:31:58.824847   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:31:58.824884   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:58.824895   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:31:58.824909   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:31:58.825013   95247 eligibility.go:167] Node ip-10-180-146-219.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:31:58.825033   95247 klogx.go:87] Node ip-10-180-146-219.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:31:58.825058   95247 cluster.go:156] Simulating node ip-10-180-146-219.eu-west-1.compute.internal removal
I1129 14:31:58.825123   95247 cluster.go:174] node ip-10-180-146-219.eu-west-1.compute.internal may be removed
I1129 14:31:58.825146   95247 nodes.go:84] ip-10-180-146-219.eu-west-1.compute.internal is unneeded since 2024-11-29 14:31:58.820854 +0530 IST m=+1036.518124251 duration 0s
I1129 14:31:58.825194   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:31:58.825220   95247 static_autoscaler.go:647] Starting scale down
I1129 14:31:58.825305   95247 nodes.go:126] ip-10-180-146-219.eu-west-1.compute.internal was unneeded for 0s
I1129 14:31:58.825376   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:31:59.267731   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-146-219.eu-west-1.compute.internal
I1129 14:32:09.724956   95247 static_autoscaler.go:306] Starting main loop
I1129 14:32:09.725195   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:09.725311   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:09.726279   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:09.726307   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:09.726349   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:09.727427   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:09.727460   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:09.727484   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:09.728114   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:09.728178   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-146-219.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7839020Ki
I1129 14:32:09.728216   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:09.728925   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:32:09.729595   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:09.729772   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:32:09.729798   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:32:09.729821   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:32:09.729833   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:32:09.729843   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:32:09.729878   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:32:09.729913   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:32:09.729956   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:09.730005   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:32:09.730037   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:32:09.730215   95247 eligibility.go:167] Node ip-10-180-146-219.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:32:09.730247   95247 klogx.go:87] Node ip-10-180-146-219.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:32:09.730279   95247 cluster.go:156] Simulating node ip-10-180-146-219.eu-west-1.compute.internal removal
I1129 14:32:09.730367   95247 cluster.go:174] node ip-10-180-146-219.eu-west-1.compute.internal may be removed
I1129 14:32:09.730410   95247 nodes.go:84] ip-10-180-146-219.eu-west-1.compute.internal is unneeded since 2024-11-29 14:31:58.820854 +0530 IST m=+1036.518124251 duration 10.904056584s
I1129 14:32:09.730494   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:29:20.694775 +0530 IST m=+878.390785126 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:32:09.730597   95247 static_autoscaler.go:647] Starting scale down
I1129 14:32:09.730658   95247 nodes.go:126] ip-10-180-146-219.eu-west-1.compute.internal was unneeded for 10.904056584s
I1129 14:32:09.730746   95247 klogx.go:87] Considering node ip-10-180-146-219.eu-west-1.compute.internal for standard scale down
I1129 14:32:10.175670   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-146-219.eu-west-1.compute.internal
I1129 14:32:10.175742   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-146-219.eu-west-1.compute.internal"
I1129 14:32:10.175871   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-146-219.eu-west-1.compute.internal", UID:"699919a6-e977-4b1f-b8df-3fd038af984e", APIVersion:"v1", ResourceVersion:"17049", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:32:10.175985   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:32:10.406001   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"17056", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-146-219.eu-west-1.compute.internal"
I1129 14:32:15.177702   95247 drain.go:131] All pods removed from ip-10-180-146-219.eu-west-1.compute.internal
I1129 14:32:15.177850   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-146-219.eu-west-1.compute.internal]
I1129 14:32:16.123383   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-three-zones-z2-967d8-lg72f marked with priority 1 successfully
I1129 14:32:16.123431   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-three-zones-z2-967d8-lg72f:ip-10-180-146-219.eu-west-1.compute.internal]
I1129 14:32:16.653269   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-three-zones-z2 size decreased to 0 
I1129 14:32:16.653583   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"17132", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-146-219.eu-west-1.compute.internal removed
I1129 14:32:20.635338   95247 static_autoscaler.go:306] Starting main loop
I1129 14:32:20.635530   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:20.635589   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:20.636592   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:32:20.637511   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:20.637536   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:20.637564   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:20.638168   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:20.638188   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:20.638208   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:20.638741   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:20.638757   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:20.638777   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:20.639412   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:20.639541   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:32:20.639563   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:32:20.639583   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:32:20.639595   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:32:20.639607   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:32:20.639641   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:32:20.639676   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:32:20.639717   95247 pre_filtering_processor.go:67] Skipping ip-10-180-146-219.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:32:20.639741   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:20.639754   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:32:20.639774   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:32:20.639852   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:32:20.974952   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.Machine total 105 items received
I1129 14:32:31.090753   95247 static_autoscaler.go:306] Starting main loop
I1129 14:32:31.091054   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:31.091121   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:31.091957   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:32:31.092805   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:31.092825   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:31.092844   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:31.093255   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:31.093266   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:31.093275   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:31.093625   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:31.093636   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:31.093644   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:31.094092   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:31.094172   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:32:31.094195   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:32:31.094208   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:32:31.094215   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:32:31.094219   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:32:31.094234   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:32:31.094247   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:32:31.094269   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:32:31.094281   95247 pre_filtering_processor.go:67] Skipping ip-10-180-146-219.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:32:31.094289   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:31.094294   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:32:31.094339   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:32:41.550797   95247 static_autoscaler.go:306] Starting main loop
I1129 14:32:41.551022   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:41.551101   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:41.552045   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:41.552078   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:41.552173   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:41.553193   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:41.553219   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:41.553242   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:41.553935   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:32:41.554670   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:41.554692   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:41.554713   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:41.555526   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:41.555675   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:32:41.555698   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:32:41.555738   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:32:41.555750   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:32:41.555760   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:32:41.555794   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:32:41.555829   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:32:41.555861   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:41.555881   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:32:41.555904   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:32:41.555925   95247 pre_filtering_processor.go:67] Skipping ip-10-180-146-219.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:32:41.556004   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:32:45.908202   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:32:45.908354   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 99.709Âµs
I1129 14:32:52.101924   95247 static_autoscaler.go:306] Starting main loop
I1129 14:32:52.102194   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:52.102248   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:32:52.102941   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:52.102964   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:52.102999   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:52.103724   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:32:52.104271   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:52.104287   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:52.104302   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:52.104903   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:32:52.104920   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:32:52.104935   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:32:52.105536   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:52.105561   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:32:52.105580   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:32:52.105599   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:32:52.105663   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:32:52.105688   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:32:52.105700   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:32:52.105715   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:32:52.105767   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:32:52.105988   95247 klogx.go:87] failed to find place for default/large-scale-up-pod-ccd4fd8d8-6fnkw: cannot put pod large-scale-up-pod-ccd4fd8d8-6fnkw on any node
I1129 14:32:52.106024   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:32:52.106048   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:32:52.106074   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:32:52.106085   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:32:52.106104   95247 klogx.go:87] Pod default/large-scale-up-pod-ccd4fd8d8-6fnkw is unschedulable
I1129 14:32:52.106143   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:32:52.106473   95247 orchestrator.go:595] Pod default/large-scale-up-pod-ccd4fd8d8-6fnkw can't be scheduled on shoot--i544000--ca-it-three-zones-z2, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I1129 14:32:52.106640   95247 orchestrator.go:595] Pod default/large-scale-up-pod-ccd4fd8d8-6fnkw can't be scheduled on shoot--i544000--ca-it-three-zones-z3, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I1129 14:32:52.106796   95247 orchestrator.go:595] Pod default/large-scale-up-pod-ccd4fd8d8-6fnkw can't be scheduled on shoot--i544000--ca-it-one-zone-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:32:52.106910   95247 orchestrator.go:595] Pod default/large-scale-up-pod-ccd4fd8d8-6fnkw can't be scheduled on shoot--i544000--ca-it-three-zones-z1, predicate checking error: Insufficient cpu; predicateName=NodeResourcesFit; reasons: Insufficient cpu; debugInfo=
I1129 14:32:52.106927   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z2
I1129 14:32:52.106935   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z3
I1129 14:32:52.106942   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-one-zone-z1
I1129 14:32:52.106947   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z1
I1129 14:32:52.106959   95247 orchestrator.go:169] No expansion options
I1129 14:32:52.107026   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:32:52.107062   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:32:52.107083   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:32:52.107092   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:32:52.107107   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"large-scale-up-pod-ccd4fd8d8-6fnkw", UID:"1e421470-9c77-41a1-ab91-d24966e58e53", APIVersion:"v1", ResourceVersion:"17374", FieldPath:""}): type: 'Normal' reason: 'NotTriggerScaleUp' pod didn't trigger scale-up: 1 node(s) didn't match Pod's node affinity/selector, 3 Insufficient cpu
I1129 14:32:52.107182   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:30:02.973284 +0530 IST m=+920.669630876 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:33:02.647474   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:02.647698   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:02.647748   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:02.648388   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:02.649308   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:02.649333   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:02.649355   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:02.650010   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:02.650032   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:02.650056   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:02.650659   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:02.650679   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:02.650701   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:02.651302   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:02.651346   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:02.651359   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:02.651378   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:02.651446   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:33:02.651471   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:02.651482   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:02.651498   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:02.651559   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:02.651789   95247 klogx.go:87] failed to find place for default/scale-up-pod-a-547c8d5884-lv26x: cannot put pod scale-up-pod-a-547c8d5884-lv26x on any node
I1129 14:33:02.651827   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:33:02.651847   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:33:02.651858   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:02.651868   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:33:02.651884   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x is unschedulable
I1129 14:33:02.651916   95247 orchestrator.go:111] Upcoming 0 nodes
I1129 14:33:02.652173   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z3, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:33:02.652470   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:33:02.652646   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z2, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:33:02.652668   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z3
I1129 14:33:02.652724   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z1-3696848528269573614 are not similar, ephemeral-storage does not match
I1129 14:33:02.652753   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z2-3331438549329573652 are not similar, ephemeral-storage does not match
I1129 14:33:02.652780   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z3-2760696778339807327 are not similar, ephemeral-storage does not match
I1129 14:33:02.653370   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z1
I1129 14:33:02.653389   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z2
I1129 14:33:02.653411   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-one-zone-z1 would waste 50.00% CPU, 98.17% Memory, 74.08% Blended
I1129 14:33:02.653444   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-one-zone-z1
I1129 14:33:02.653463   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-one-zone-z1
I1129 14:33:02.653516   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z1-3696848528269573614 are not similar, ephemeral-storage does not match
I1129 14:33:02.653548   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z2-3331438549329573652 are not similar, ephemeral-storage does not match
I1129 14:33:02.653600   95247 compare_nodegroups.go:164] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2997976403994497304 and template-node-for-shoot--i544000--ca-it-three-zones-z3-2760696778339807327 are not similar, ephemeral-storage does not match
I1129 14:33:02.653615   95247 orchestrator.go:700] No similar node groups found
I1129 14:33:02.653653   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-one-zone-z1 0->1 (max: 2)}]
I1129 14:33:02.653687   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-one-zone-z1 size to 1
I1129 14:33:02.653730   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-one-zone-z1 by 1
I1129 14:33:02.653861   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"17463", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-one-zone-z1 size to 1 instead of 0 (max: 2)
I1129 14:33:03.184397   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
W1129 14:33:03.184509   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-one-zone-z1
I1129 14:33:03.184513   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"17463", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: group shoot--i544000--ca-it-one-zone-z1 size set to 1 instead of 0 (max: 2)
I1129 14:33:03.408309   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Pod", Namespace:"default", Name:"scale-up-pod-a-547c8d5884-lv26x", UID:"f9e8cbf8-25de-4343-9d3e-7af636375bd9", APIVersion:"v1", ResourceVersion:"17485", FieldPath:""}): type: 'Normal' reason: 'TriggeredScaleUp' pod triggered scale-up: [{shoot--i544000--ca-it-one-zone-z1 0->1 (max: 2)}]
I1129 14:33:13.636038   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:13.636251   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:13.636313   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:13.637140   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:13.637999   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:13.638025   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:13.638096   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:13.638731   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:13.638757   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:13.638806   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:13.639388   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:13.639410   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:13.639430   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
W1129 14:33:13.639974   95247 clusterstate.go:495] Failed to find readiness information for shoot--i544000--ca-it-one-zone-z1
I1129 14:33:13.640048   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:13.640096   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:13.640111   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:13.640129   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:13.640195   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:33:13.640222   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:13.640235   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:13.640251   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:13.640667   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:13.640866   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-2937705246213141361-upcoming-0
I1129 14:33:13.640889   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:33:13.640909   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:33:13.640922   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:13.640932   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:33:13.640967   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:33:13.641002   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:33:13.641036   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:13.641057   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:33:13.641081   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:33:13.641156   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:33:24.093927   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:24.094160   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:24.094206   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:24.094882   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:24.094908   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:24.094952   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:24.095573   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:24.095945   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:24.095958   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:24.095970   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:24.096385   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:24.096398   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:24.096409   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:24.096881   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:24.096949   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:24.096959   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:24.096970   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:24.097026   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:33:24.097045   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:24.097052   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:24.097060   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:24.097544   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:24.097734   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-7300198580882948506-upcoming-0
I1129 14:33:24.097766   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:33:24.097780   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:33:24.097788   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:24.097793   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:33:24.097832   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:33:24.097858   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:33:24.097893   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:24.097907   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:33:24.097924   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:33:24.097980   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:33:26.974592   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineClass total 19 items received
I1129 14:33:34.547657   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:34.547958   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:34.548020   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:34.548829   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:34.548859   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:34.548900   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:34.549788   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:34.550429   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:34.550453   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:34.550475   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:34.551020   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:34.551040   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:34.551058   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:34.551764   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:34.551797   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:34.551805   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:34.551819   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:34.551885   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:33:34.551899   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:34.551907   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:34.551915   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:34.552244   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:34.552428   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-1811911724676463001-upcoming-0
I1129 14:33:34.552457   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:33:34.552472   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:33:34.552481   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:34.552486   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:33:34.552508   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:33:34.552527   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:33:34.552557   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:34.552568   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:33:34.552585   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:33:34.552639   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:33:45.007493   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:45.007721   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:45.007828   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:45.008579   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:45.008608   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:45.008650   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:45.009439   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:45.009989   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:45.010011   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:45.010031   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:45.010642   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:45.010662   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:45.010682   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:45.011367   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:45.011493   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:45.011523   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:45.011550   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:45.011631   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:33:45.011657   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:45.011669   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:45.011683   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:45.012169   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:45.012420   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-2777362106588371607-upcoming-0
I1129 14:33:45.012457   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:33:45.012480   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:33:45.012493   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:45.012503   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:33:45.012537   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:33:45.012567   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:33:45.012615   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:45.012632   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:33:45.012659   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:33:45.012740   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:33:49.108836   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Pod total 182 items received
I1129 14:33:55.508472   95247 static_autoscaler.go:306] Starting main loop
I1129 14:33:55.508742   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:55.508803   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:33:55.509627   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:55.509656   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:55.509696   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:55.510481   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:55.510504   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:55.510524   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:55.511120   95247 mcm_manager.go:791] Generating node template only using nodeTemplate from MachineClass shoot--i544000--ca-it-one-zone-z1-9d83c: template resources-> cpu: 2,memory: 8Gi
I1129 14:33:55.511684   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:33:55.511705   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:33:55.511727   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:33:55.512455   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:55.512521   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:55.512538   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:55.512557   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:33:55.512628   95247 static_autoscaler.go:439] 2 unregistered nodes present
I1129 14:33:55.512660   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:33:55.512672   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:33:55.512686   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:33:55.513126   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:33:55.513380   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-6204652929026647539-upcoming-0
I1129 14:33:55.513418   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:33:55.513440   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:33:55.513454   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:33:55.513464   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:33:55.513498   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:33:55.513533   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:33:55.513575   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:33:55.513594   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:33:55.513621   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:33:55.513702   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:34:05.967526   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:05.967793   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:05.967879   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:05.969186   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:05.969263   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:05.969306   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:05.970134   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:05.970160   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:05.970180   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:05.970775   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:05.970789   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:05.970804   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:05.971130   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:05.971141   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:05.971151   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:05.971627   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:05.971678   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:05.971686   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:05.971697   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:34:05.971760   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:05.971776   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:05.971796   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:05.971806   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:34:05.972172   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:05.972355   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-9142433162889334409-upcoming-0
I1129 14:34:05.972380   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:05.972394   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:05.972402   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:05.972409   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:34:05.972426   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:34:05.972441   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:34:05.972470   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:05.972481   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:34:05.972498   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:34:05.972551   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:34:15.112872   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StorageClass total 7 items received
I1129 14:34:16.431195   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:16.431418   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:16.431479   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:16.432439   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:16.432469   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:16.432510   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:16.433296   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:16.433319   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:16.433350   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:16.433895   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:16.433918   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:16.433937   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:16.434509   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:16.434529   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:16.434548   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:16.435341   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:16.435373   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:16.435388   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:16.435407   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:34:16.435490   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:16.435515   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:16.435532   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:16.435545   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:34:16.436017   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:16.436261   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-8914622787118948473-upcoming-0
I1129 14:34:16.436298   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:16.436320   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:16.436333   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:16.436343   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:34:16.436376   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:34:16.436410   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:34:16.436462   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:34:16.436485   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:16.436501   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:34:16.436577   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:34:22.102852   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PersistentVolume total 12 items received
I1129 14:34:24.097211   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.ReplicaSet total 24 items received
I1129 14:34:26.886752   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:26.887005   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:26.887087   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:26.888059   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:26.888088   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:26.888128   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:26.888877   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:26.888899   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:26.888924   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:26.889476   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:26.889495   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:26.889514   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:26.890032   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:26.890052   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:26.890069   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:26.890829   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:26.890889   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:26.890909   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:26.890928   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:34:26.890996   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:26.891021   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:26.891034   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:26.891048   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:34:26.891505   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:26.891747   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-3263452746578315812-upcoming-0
I1129 14:34:26.891790   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:26.891814   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:26.891827   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:26.891836   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:34:26.891871   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:34:26.891902   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:34:26.891950   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:26.891969   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:34:26.892000   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:34:26.892080   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:33:02.647399 +0530 IST m=+1100.345177460 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:34:37.342175   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:37.342372   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:37.342428   95247 taints.go:442] Overriding status of node ip-10-180-7-69.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:34:37.342495   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:38.122755   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-one-zone-z1-5897f-6bh8t marked with priority 1 successfully
I1129 14:34:38.123773   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:38.123803   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:38.123849   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:38.124619   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:38.124642   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:38.124667   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:38.125220   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:38.125240   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:38.125259   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:38.125836   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:38.125857   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:38.125879   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:38.126574   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:38.126641   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:38.126657   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:38.126676   95247 clusterstate.go:651] Nodegroup is nil for requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f
I1129 14:34:38.126755   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:38.126777   95247 mcm_cloud_provider.go:290] No machine found for node ID "requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f"
I1129 14:34:38.126789   95247 mcm_cloud_provider.go:165] Skipped node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, it's either been removed or it's not managed by this controller
W1129 14:34:38.126803   95247 static_autoscaler.go:786] No node group for node requested://shoot--i544000--ca-it-three-zones-z2-967d8-lg72f, skipping
I1129 14:34:38.127314   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:38.127517   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299-upcoming-0
I1129 14:34:38.127625   95247 klogx.go:87] failed to find place for default/scale-up-pod-a-547c8d5884-lv26x: cannot put pod scale-up-pod-a-547c8d5884-lv26x on any node
I1129 14:34:38.127648   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:38.127670   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:38.127684   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:38.127693   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 1 unschedulable pods left
I1129 14:34:38.127711   95247 klogx.go:87] Pod default/scale-up-pod-a-547c8d5884-lv26x is unschedulable
I1129 14:34:38.127748   95247 orchestrator.go:111] Upcoming 1 nodes
I1129 14:34:38.128117   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z1, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:34:38.128264   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z2, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:34:38.128452   95247 orchestrator.go:595] Pod default/scale-up-pod-a-547c8d5884-lv26x can't be scheduled on shoot--i544000--ca-it-three-zones-z3, predicate checking error: node(s) didn't match Pod's node affinity/selector; predicateName=NodeAffinity; reasons: node(s) didn't match Pod's node affinity/selector; debugInfo=
I1129 14:34:38.128551   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z1-2136079361475235245 are not similar, labels do not match
I1129 14:34:38.128605   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z2-4035641655191823381 are not similar, labels do not match
I1129 14:34:38.128651   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z3-399769850277270655 are not similar, labels do not match
I1129 14:34:38.129300   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z1
I1129 14:34:38.129317   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z2
I1129 14:34:38.129330   95247 orchestrator.go:153] No pod can fit to shoot--i544000--ca-it-three-zones-z3
I1129 14:34:38.129352   95247 waste.go:55] Expanding Node Group shoot--i544000--ca-it-one-zone-z1 would waste 50.00% CPU, 98.06% Memory, 74.03% Blended
I1129 14:34:38.129386   95247 orchestrator.go:186] Best option to resize: shoot--i544000--ca-it-one-zone-z1
I1129 14:34:38.129405   95247 orchestrator.go:190] Estimated 1 nodes needed in shoot--i544000--ca-it-one-zone-z1
I1129 14:34:38.129479   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z1-2136079361475235245 are not similar, labels do not match
I1129 14:34:38.129532   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z2-4035641655191823381 are not similar, labels do not match
I1129 14:34:38.129576   95247 compare_nodegroups.go:181] nodes template-node-for-shoot--i544000--ca-it-one-zone-z1-2942112733755596299 and template-node-for-shoot--i544000--ca-it-three-zones-z3-399769850277270655 are not similar, labels do not match
I1129 14:34:38.129593   95247 orchestrator.go:700] No similar node groups found
I1129 14:34:38.129629   95247 orchestrator.go:255] Final scale-up plan: [{shoot--i544000--ca-it-one-zone-z1 1->2 (max: 2)}]
I1129 14:34:38.129660   95247 executor.go:166] Scale-up: setting group shoot--i544000--ca-it-one-zone-z1 size to 2
I1129 14:34:38.129699   95247 mcm_cloud_provider.go:351] Received request to increase size of machine deployment shoot--i544000--ca-it-one-zone-z1 by 1
I1129 14:34:38.129842   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"18274", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' Scale-up: setting group shoot--i544000--ca-it-one-zone-z1 size to 2 instead of 1 (max: 2)
I1129 14:34:38.660756   95247 eventing_scale_up_processor.go:47] Skipping event processing for unschedulable pods since there is a ScaleUp attempt this loop
I1129 14:34:38.660815   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"18274", FieldPath:""}): type: 'Normal' reason: 'ScaledUpGroup' (combined from similar events): Scale-up: group shoot--i544000--ca-it-one-zone-z1 size set to 2 instead of 1 (max: 2)
I1129 14:34:41.109263   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.PodDisruptionBudget total 0 items received
I1129 14:34:45.907675   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:34:45.907927   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 141.167Âµs
I1129 14:34:49.111501   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:49.111790   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:49.111855   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:49.112846   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:49.112875   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:49.112921   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:49.113752   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:49.113777   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:49.113800   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:49.114397   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:49.114417   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:49.114439   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:49.115090   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:49.115110   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:49.115127   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:49.115940   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:49.116057   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:49.116540   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:49.116797   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-5912399437215009905-upcoming-0
I1129 14:34:49.116834   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:49.116848   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:49.116857   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:49.116862   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:34:49.116880   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:34:49.116899   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:34:49.116928   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:49.116941   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:34:49.116960   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:34:49.117062   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:34:49.117118   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:34:49.117164   95247 static_autoscaler.go:647] Starting scale down
I1129 14:34:49.117231   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:52.145577   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Job total 3 items received
I1129 14:34:59.588327   95247 static_autoscaler.go:306] Starting main loop
I1129 14:34:59.588464   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:59.588493   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:34:59.588919   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:34:59.588936   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:59.588986   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:59.589470   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:59.589485   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:59.589497   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:59.589830   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:59.589840   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:59.589849   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:59.590090   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:34:59.590099   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:34:59.590108   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:34:59.590439   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:59.590494   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:34:59.590743   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:34:59.590849   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-7426312699679051462-upcoming-0
I1129 14:34:59.590865   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:34:59.590875   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:34:59.590881   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:34:59.590885   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:34:59.590898   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:34:59.590910   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:34:59.590949   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:34:59.590960   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:34:59.590971   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:34:59.591041   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:34:59.591079   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:34:59.591107   95247 static_autoscaler.go:647] Starting scale down
I1129 14:34:59.591163   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:10.044684   95247 static_autoscaler.go:306] Starting main loop
I1129 14:35:10.044850   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:10.044886   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:10.045641   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:35:10.045660   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:10.045689   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:10.046236   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:10.046257   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:10.046268   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:10.046559   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:10.046571   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:10.046580   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:10.046825   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:10.046834   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:10.046841   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:10.047238   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:10.047306   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:35:10.047614   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:35:10.047835   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-2367352882469063514-upcoming-0
I1129 14:35:10.047847   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:35:10.047857   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:35:10.047864   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:35:10.047868   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:35:10.047881   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:35:10.047895   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:35:10.047920   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:10.047931   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:10.047949   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:35:10.048053   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:35:10.048108   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:35:10.048143   95247 static_autoscaler.go:647] Starting scale down
I1129 14:35:10.048200   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:18.106551   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 108 items received
I1129 14:35:20.502552   95247 static_autoscaler.go:306] Starting main loop
I1129 14:35:20.502834   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:20.502901   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:20.503885   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:35:20.503914   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:20.503954   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:20.505016   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:20.505046   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:20.505075   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:20.505696   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:20.505717   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:20.505740   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:20.506316   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:20.506336   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:20.506355   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:20.507157   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:20.507289   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:35:20.507797   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:35:20.508042   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-7250386800682778077-upcoming-0
I1129 14:35:20.508074   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:35:20.508096   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:35:20.508109   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:35:20.508118   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:35:20.508152   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:35:20.508187   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:35:20.508244   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:20.508267   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:20.508297   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:35:20.508435   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:35:20.508514   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:35:20.508584   95247 static_autoscaler.go:647] Starting scale down
I1129 14:35:20.508693   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:25.100781   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIDriver total 9 items received
I1129 14:35:30.963529   95247 static_autoscaler.go:306] Starting main loop
I1129 14:35:30.963796   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:30.963867   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:30.966032   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:30.966062   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:30.966095   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:30.966893   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:30.966915   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:30.966934   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:30.967503   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:30.967524   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:30.967542   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:30.968181   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:30.968306   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:35:30.969026   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:35:30.969297   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-4084461790154640548-upcoming-0
I1129 14:35:30.969335   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:35:30.969359   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:35:30.969372   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:35:30.969380   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:35:30.969415   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:35:30.969447   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:35:30.969491   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:30.969508   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:30.969537   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:35:30.969683   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:35:30.969763   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:35:30.969830   95247 static_autoscaler.go:647] Starting scale down
I1129 14:35:30.969926   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:31.063940   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Deployment total 40 items received
I1129 14:35:41.425179   95247 static_autoscaler.go:306] Starting main loop
I1129 14:35:41.425512   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:41.425589   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:41.428130   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:41.428159   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:41.428191   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:41.428989   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:41.429011   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:41.429030   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:41.429640   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:41.429661   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:41.429685   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:41.430407   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
W1129 14:35:41.430456   95247 mcm_cloud_provider.go:155] Node ip-10-180-26-233.eu-west-1.compute.internal has no providerId
I1129 14:35:41.431195   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:35:41.431441   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-6393703992207550302-upcoming-0
I1129 14:35:41.431460   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:35:41.431475   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:35:41.431485   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:35:41.431492   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:35:41.431517   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:35:41.431539   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:35:41.431568   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:41.431583   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:41.431603   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
W1129 14:35:41.431617   95247 mcm_cloud_provider.go:155] Node ip-10-180-26-233.eu-west-1.compute.internal has no providerId
I1129 14:35:41.431626   95247 pre_filtering_processor.go:57] Node ip-10-180-26-233.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:41.431726   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:35:41.431794   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:35:41.431845   95247 static_autoscaler.go:647] Starting scale down
I1129 14:35:41.431961   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
W1129 14:35:41.431991   95247 mcm_cloud_provider.go:155] Node ip-10-180-26-233.eu-west-1.compute.internal has no providerId
I1129 14:35:44.236857   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.MachineSet total 32 items received
I1129 14:35:52.738864   95247 static_autoscaler.go:306] Starting main loop
I1129 14:35:52.739219   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:52.739299   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:35:52.741689   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:52.741719   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:52.741756   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:52.742469   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:52.742493   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:52.742515   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:52.743057   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:35:52.743080   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:35:52.743099   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:35:52.743899   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:52.744597   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:35:52.744892   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-1806892963156426046-upcoming-0
I1129 14:35:52.744929   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:35:52.744951   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:35:52.744966   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:35:52.744976   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:35:52.745012   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:35:52.745043   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:35:52.745098   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:35:52.745134   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:35:52.745149   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:35:52.745288   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:35:52.745372   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:35:52.745440   95247 static_autoscaler.go:647] Starting scale down
I1129 14:35:52.745557   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:03.200638   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:03.200971   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:03.201061   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:03.203443   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:03.203473   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:03.203516   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:03.204215   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:03.204239   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:03.204261   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:03.204874   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:03.204896   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:03.204915   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:03.205549   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:03.206301   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:03.206527   95247 klogx.go:87] Pod default/scale-up-pod-b-547c8d5884-kd8l4 can be moved to template-node-for-shoot--i544000--ca-it-one-zone-z1-2040872695192244997-upcoming-0
I1129 14:36:03.206574   95247 filter_out_schedulable.go:123] 1 pods marked as unschedulable can be scheduled.
I1129 14:36:03.206597   95247 filter_out_schedulable.go:78] Schedulable pods present
I1129 14:36:03.206610   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:03.206620   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:03.206655   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:03.206688   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:03.206749   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:03.206765   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:03.206794   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:03.206948   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:03.207032   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:03.207095   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:03.207189   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:09.099183   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Namespace total 8 items received
I1129 14:36:10.103151   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.StatefulSet total 6 items received
I1129 14:36:13.734457   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:13.734746   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:13.734814   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:13.734860   95247 taints.go:442] Overriding status of node ip-10-180-26-233.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:36:13.737400   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:13.737429   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:13.737462   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:13.738173   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:13.738193   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:13.738213   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:13.738856   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:13.738887   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:13.738947   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:13.739769   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:13.740546   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:13.740574   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:36:13.740595   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:36:13.740608   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:13.740618   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:13.740653   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:13.740720   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:13.740761   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:13.740779   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:13.740806   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:13.740953   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:13.741036   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:13.741105   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:13.741195   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:20.119700   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.DaemonSet total 104 items received
I1129 14:36:24.194103   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:24.194324   95247 taints.go:442] Overriding status of node ip-10-180-26-233.eu-west-1.compute.internal, which seems to have startup taint "node.gardener.cloud/critical-components-not-ready"
I1129 14:36:24.194394   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:24.194451   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:24.196883   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:24.196912   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:24.196950   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:24.197658   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:24.197680   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:24.197717   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:24.198372   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:24.198393   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:24.198414   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:24.199078   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:24.199838   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:24.199862   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:36:24.199887   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:36:24.199899   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:24.199908   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:24.199941   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:24.199972   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:24.200007   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:24.200027   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:24.200051   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:24.200182   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:24.200261   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:24.200328   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:24.200417   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:34.659847   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:34.660092   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:34.660173   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:34.662695   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:34.662724   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:34.662759   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:34.663443   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:34.663463   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:34.663484   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:34.664049   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:34.664072   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:34.664098   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:34.664928   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:34.665011   95247 clusterstate.go:269] Scale up in group shoot--i544000--ca-it-one-zone-z1 finished successfully in 1m56.000035708s
I1129 14:36:34.665108   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:34.665131   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:36:34.665153   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:36:34.665165   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:34.665174   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:34.665208   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:34.665243   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:34.665275   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:34.665294   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:34.665318   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:34.665524   95247 eligibility.go:167] Node ip-10-180-26-233.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:36:34.665554   95247 klogx.go:87] Node ip-10-180-26-233.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:36:34.665650   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:34.665685   95247 cluster.go:156] Simulating node ip-10-180-26-233.eu-west-1.compute.internal removal
I1129 14:36:34.665748   95247 cluster.go:174] node ip-10-180-26-233.eu-west-1.compute.internal may be removed
I1129 14:36:34.665780   95247 nodes.go:84] ip-10-180-26-233.eu-west-1.compute.internal is unneeded since 2024-11-29 14:36:34.659767 +0530 IST m=+1312.359235418 duration 0s
I1129 14:36:34.665858   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:34.665932   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:34.665978   95247 nodes.go:126] ip-10-180-26-233.eu-west-1.compute.internal was unneeded for 0s
I1129 14:36:34.666056   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:35.110731   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-26-233.eu-west-1.compute.internal
I1129 14:36:36.099681   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSIStorageCapacity total 5 items received
I1129 14:36:45.572295   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:45.573174   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:45.573259   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:45.576613   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:45.576650   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:45.576699   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:45.578227   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:45.578251   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:45.578277   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:45.579510   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:45.579531   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:45.579566   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:45.582355   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:45.582500   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:45.582521   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:36:45.582554   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:36:45.582567   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:45.582598   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:45.582635   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:45.582667   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:45.582732   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:45.582791   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:45.582803   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:45.583139   95247 eligibility.go:167] Node ip-10-180-26-233.eu-west-1.compute.internal is underutilized: cpu requested (21.25% of allocatable) is below the scale-down utilization threshold
I1129 14:36:45.583175   95247 klogx.go:87] Node ip-10-180-26-233.eu-west-1.compute.internal - cpu requested is 21.25% of allocatable
I1129 14:36:45.583357   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:45.583394   95247 cluster.go:156] Simulating node ip-10-180-26-233.eu-west-1.compute.internal removal
I1129 14:36:45.583487   95247 cluster.go:174] node ip-10-180-26-233.eu-west-1.compute.internal may be removed
I1129 14:36:45.583530   95247 nodes.go:84] ip-10-180-26-233.eu-west-1.compute.internal is unneeded since 2024-11-29 14:36:34.659767 +0530 IST m=+1312.359235418 duration 10.912500417s
I1129 14:36:45.583633   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:32:09.724824 +0530 IST m=+1047.422180835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:45.583724   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:45.583767   95247 nodes.go:126] ip-10-180-26-233.eu-west-1.compute.internal was unneeded for 10.912500417s
I1129 14:36:45.583801   95247 klogx.go:87] Considering node ip-10-180-26-233.eu-west-1.compute.internal for standard scale down
I1129 14:36:45.908030   95247 node_instances_cache.go:156] Start refreshing cloud provider node instances cache
I1129 14:36:45.908474   95247 node_instances_cache.go:168] Refresh cloud provider node instances cache finished, refresh took 151.833Âµs
I1129 14:36:46.037507   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-26-233.eu-west-1.compute.internal
I1129 14:36:46.037583   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-26-233.eu-west-1.compute.internal"
I1129 14:36:46.037831   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-26-233.eu-west-1.compute.internal", UID:"8c4a0776-c14f-434e-a582-a01d7d95c116", APIVersion:"v1", ResourceVersion:"19469", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:36:46.038064   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:36:46.263760   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"19421", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-26-233.eu-west-1.compute.internal"
I1129 14:36:51.041681   95247 drain.go:131] All pods removed from ip-10-180-26-233.eu-west-1.compute.internal
I1129 14:36:51.041805   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-26-233.eu-west-1.compute.internal]
I1129 14:36:52.092976   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-one-zone-z1-5897f-wq4rm marked with priority 1 successfully
I1129 14:36:52.093045   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-one-zone-z1-5897f-wq4rm:ip-10-180-26-233.eu-west-1.compute.internal]
I1129 14:36:52.676197   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-one-zone-z1 size decreased to 1 
I1129 14:36:52.676651   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"19527", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-26-233.eu-west-1.compute.internal removed
I1129 14:36:56.537370   95247 static_autoscaler.go:306] Starting main loop
I1129 14:36:56.537692   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:56.537760   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:36:56.540472   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:56.540505   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:56.540542   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:56.541283   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:56.541306   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:56.541325   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:56.542008   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:36:56.542030   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:36:56.542050   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:36:56.542765   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:56.542901   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:36:56.542924   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:36:56.542944   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:36:56.542956   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:36:56.542965   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:36:56.542998   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:36:56.543029   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:36:56.543078   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:36:56.543095   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:36:56.543117   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:36:56.543237   95247 eligibility.go:113] Skipping ip-10-180-26-233.eu-west-1.compute.internal from delete consideration - the node is currently being deleted
I1129 14:36:56.543341   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:36:56.543419   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:36:45.57218 +0530 IST m=+1323.271735835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:36:56.543502   95247 static_autoscaler.go:647] Starting scale down
I1129 14:36:56.543614   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:06.195367   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.Node total 139 items received
I1129 14:37:07.002977   95247 static_autoscaler.go:306] Starting main loop
I1129 14:37:07.003233   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:07.003292   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:07.006101   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:07.006131   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:07.006163   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:07.006911   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:07.006935   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:07.006955   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:07.007570   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:07.007593   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:07.007611   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:07.008171   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:07.008314   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:37:07.008336   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:37:07.008357   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:37:07.008369   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:37:07.008377   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:37:07.008411   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:37:07.008445   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:37:07.008473   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:07.008492   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:37:07.008517   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:37:07.008638   95247 eligibility.go:113] Skipping ip-10-180-26-233.eu-west-1.compute.internal from delete consideration - the node is currently being deleted
I1129 14:37:07.008737   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:37:07.008814   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:36:45.57218 +0530 IST m=+1323.271735835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:37:07.008881   95247 static_autoscaler.go:647] Starting scale down
I1129 14:37:07.008971   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:17.465223   95247 static_autoscaler.go:306] Starting main loop
I1129 14:37:17.465559   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:17.465632   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:17.468144   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:17.468176   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:17.468214   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:17.468915   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:17.468936   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:17.468956   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:17.469477   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:17.469497   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:17.469516   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:17.470077   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:17.470220   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:37:17.470243   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:37:17.470266   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:37:17.470279   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:37:17.470289   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:37:17.470323   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:37:17.470358   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:37:17.470392   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:17.470409   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:37:17.470435   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:37:17.470559   95247 eligibility.go:113] Skipping ip-10-180-26-233.eu-west-1.compute.internal from delete consideration - the node is currently being deleted
I1129 14:37:17.470660   95247 eligibility.go:162] Node ip-10-180-7-69.eu-west-1.compute.internal unremovable: cpu requested (73.1771% of allocatable) is above the scale-down utilization threshold
I1129 14:37:17.470734   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:36:45.57218 +0530 IST m=+1323.271735835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:37:17.470809   95247 static_autoscaler.go:647] Starting scale down
I1129 14:37:17.470896   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:27.924448   95247 static_autoscaler.go:306] Starting main loop
I1129 14:37:27.924767   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:27.924832   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:27.927228   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:27.927269   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:27.927307   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:27.928116   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:27.928138   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:27.928157   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:27.928718   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:27.928740   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:27.928759   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:27.929362   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:27.929405   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:27.929418   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:27.929437   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-02e9dc684fa749102
I1129 14:37:27.929504   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:37:27.929530   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:27.929544   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:27.929557   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-02e9dc684fa749102, skipping
I1129 14:37:27.929612   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:37:27.929635   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:37:27.929654   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:37:27.929666   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:37:27.929674   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:37:27.929706   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:37:27.929737   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:37:27.929786   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:27.929802   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:37:27.929826   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:37:27.929945   95247 eligibility.go:167] Node ip-10-180-7-69.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:37:27.929973   95247 klogx.go:87] Node ip-10-180-7-69.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:37:27.930003   95247 cluster.go:156] Simulating node ip-10-180-7-69.eu-west-1.compute.internal removal
I1129 14:37:27.930065   95247 cluster.go:174] node ip-10-180-7-69.eu-west-1.compute.internal may be removed
I1129 14:37:27.930098   95247 nodes.go:84] ip-10-180-7-69.eu-west-1.compute.internal is unneeded since 2024-11-29 14:37:27.924372 +0530 IST m=+1365.604806501 duration 0s
I1129 14:37:27.930177   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:36:45.57218 +0530 IST m=+1323.271735835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:37:27.930237   95247 static_autoscaler.go:647] Starting scale down
I1129 14:37:27.930283   95247 nodes.go:126] ip-10-180-7-69.eu-west-1.compute.internal was unneeded for 0s
I1129 14:37:27.930368   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:28.386423   95247 taints.go:217] Successfully added DeletionCandidateOfClusterAutoscaler on node ip-10-180-7-69.eu-west-1.compute.internal
I1129 14:37:31.126671   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1.CSINode total 16 items received
I1129 14:37:38.840262   95247 static_autoscaler.go:306] Starting main loop
I1129 14:37:38.840579   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:38.840637   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:38.841721   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:37:38.843120   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:38.843146   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:38.843220   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:38.843964   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:38.843988   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:38.844010   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:38.844556   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:38.844576   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:38.844596   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:38.845156   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:38.845216   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:38.845231   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:38.845249   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-02e9dc684fa749102
I1129 14:37:38.845316   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:37:38.845339   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:38.845353   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:38.845366   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-02e9dc684fa749102, skipping
I1129 14:37:38.845417   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:37:38.845439   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:37:38.845456   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:37:38.845467   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:37:38.845475   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:37:38.845508   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:37:38.845543   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:37:38.845580   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:38.845595   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:37:38.845618   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:37:38.845750   95247 eligibility.go:167] Node ip-10-180-7-69.eu-west-1.compute.internal is underutilized: cpu requested (21.0938% of allocatable) is below the scale-down utilization threshold
I1129 14:37:38.845779   95247 klogx.go:87] Node ip-10-180-7-69.eu-west-1.compute.internal - cpu requested is 21.0938% of allocatable
I1129 14:37:38.845820   95247 cluster.go:156] Simulating node ip-10-180-7-69.eu-west-1.compute.internal removal
I1129 14:37:38.845884   95247 cluster.go:174] node ip-10-180-7-69.eu-west-1.compute.internal may be removed
I1129 14:37:38.845922   95247 nodes.go:84] ip-10-180-7-69.eu-west-1.compute.internal is unneeded since 2024-11-29 14:37:27.924372 +0530 IST m=+1365.604806501 duration 10.914968167s
I1129 14:37:38.846004   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:36:45.57218 +0530 IST m=+1323.271735835 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=false
I1129 14:37:38.846063   95247 static_autoscaler.go:647] Starting scale down
I1129 14:37:38.846111   95247 nodes.go:126] ip-10-180-7-69.eu-west-1.compute.internal was unneeded for 10.914968167s
I1129 14:37:38.846159   95247 klogx.go:87] Considering node ip-10-180-7-69.eu-west-1.compute.internal for standard scale down
I1129 14:37:39.300906   95247 taints.go:217] Successfully added ToBeDeletedByClusterAutoscaler on node ip-10-180-7-69.eu-west-1.compute.internal
I1129 14:37:39.300988   95247 actuator.go:156] Scale-down: removing empty node "ip-10-180-7-69.eu-west-1.compute.internal"
I1129 14:37:39.301092   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"ip-10-180-7-69.eu-west-1.compute.internal", UID:"b10bbf48-67ea-4afb-9bd6-88f4a8fb7e07", APIVersion:"v1", ResourceVersion:"19841", FieldPath:""}): type: 'Normal' reason: 'ScaleDown' marked the node as toBeDeleted/unschedulable
I1129 14:37:39.301304   95247 actuator.go:254] Scale-down: waiting 5s before trying to delete nodes
I1129 14:37:39.525427   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"19847", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: removing empty node "ip-10-180-7-69.eu-west-1.compute.internal"
I1129 14:37:44.302212   95247 drain.go:131] All pods removed from ip-10-180-7-69.eu-west-1.compute.internal
I1129 14:37:44.302345   95247 mcm_cloud_provider.go:416] Received request to delete nodes:- [ip-10-180-7-69.eu-west-1.compute.internal]
I1129 14:37:45.100368   95247 mcm_manager.go:573] Machine shoot--i544000--ca-it-one-zone-z1-5897f-6bh8t marked with priority 1 successfully
I1129 14:37:45.100424   95247 mcm_manager.go:545] Expected to remove following {machineRef: corresponding node} pairs map[shoot--i544000--ca-it-one-zone-z1-5897f-6bh8t:ip-10-180-7-69.eu-west-1.compute.internal]
I1129 14:37:45.734057   95247 mcm_manager.go:599] MachineDeployment shoot--i544000--ca-it-one-zone-z1 size decreased to 0 
I1129 14:37:45.734511   95247 event_sink_logging_wrapper.go:48] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"kube-system", Name:"cluster-autoscaler-status", UID:"8ab347f6-6973-4f90-a809-0f8e59975725", APIVersion:"v1", ResourceVersion:"19919", FieldPath:""}): type: 'Normal' reason: 'ScaleDownEmpty' (combined from similar events): Scale-down: empty node ip-10-180-7-69.eu-west-1.compute.internal removed
I1129 14:37:49.755160   95247 static_autoscaler.go:306] Starting main loop
I1129 14:37:49.755532   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:49.755606   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:37:49.756667   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:37:49.756687   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:37:49.758012   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:49.758039   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:49.758073   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:49.758809   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:49.758829   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:49.758850   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:49.759503   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:37:49.759519   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:37:49.759539   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:37:49.760211   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:49.760268   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:49.760282   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:49.760300   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-02e9dc684fa749102
I1129 14:37:49.760367   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:37:49.760391   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:37:49.760404   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:37:49.760417   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-02e9dc684fa749102, skipping
I1129 14:37:49.760467   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:37:49.760489   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:37:49.760509   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:37:49.760520   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:37:49.760529   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:37:49.760561   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:37:49.760591   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:37:49.760631   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:37:49.760654   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:37:49.760679   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:37:49.760704   95247 pre_filtering_processor.go:67] Skipping ip-10-180-7-69.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:37:49.760777   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:37:38.840165 +0530 IST m=+1376.519774668 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:38:00.213085   95247 static_autoscaler.go:306] Starting main loop
I1129 14:38:00.213433   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:38:00.213505   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:38:00.214692   95247 taints.go:406] Removing autoscaler soft taint when creating template from node
I1129 14:38:00.214712   95247 taints.go:403] Removing autoscaler taint when creating template from node
I1129 14:38:00.215965   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:00.215993   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:00.216067   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:00.216823   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:00.216848   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:00.216873   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:00.217482   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:00.217503   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:00.217525   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:00.218111   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:38:00.218180   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:38:00.218194   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:38:00.218216   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-02e9dc684fa749102
I1129 14:38:00.218289   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:38:00.218313   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:38:00.218326   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:38:00.218340   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-02e9dc684fa749102, skipping
I1129 14:38:00.218391   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:38:00.218410   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:38:00.218429   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:38:00.218440   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:38:00.218451   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:38:00.218484   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:38:00.218519   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:38:00.218554   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:38:00.218570   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:38:00.218597   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:38:00.218614   95247 pre_filtering_processor.go:67] Skipping ip-10-180-7-69.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:38:00.218706   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:37:38.840165 +0530 IST m=+1376.519774668 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:38:10.687222   95247 static_autoscaler.go:306] Starting main loop
I1129 14:38:10.687566   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:38:10.687661   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:38:10.688717   95247 mcm_manager.go:778] Nodes already existing in the worker pool one-zone
I1129 14:38:10.688746   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-7-69.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:10.688786   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:10.689706   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:10.689733   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:10.689757   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:10.690354   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:10.690379   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:10.690399   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:10.691098   95247 mcm_manager.go:778] Nodes already existing in the worker pool three-zones
I1129 14:38:10.691127   95247 mcm_manager.go:780] Worker pool node used to form template is ip-10-180-89-70.eu-west-1.compute.internal and its capacity is cpu: 2, memory:7925036Ki
I1129 14:38:10.691153   95247 mcm_manager.go:981] Copying extended resources map[hugepages-1Gi:{{0 0} {<nil>} 0 DecimalSI} hugepages-2Mi:{{0 0} {<nil>} 0 DecimalSI}] to template node.Status.Capacity
I1129 14:38:10.691927   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:38:10.691955   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:38:10.691973   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:38:10.691991   95247 clusterstate.go:651] Nodegroup is nil for aws:///eu-west-1c/i-02e9dc684fa749102
I1129 14:38:10.692065   95247 static_autoscaler.go:439] 1 unregistered nodes present
I1129 14:38:10.692090   95247 mcm_cloud_provider.go:290] No machine found for node ID "aws:///eu-west-1c/i-02e9dc684fa749102"
I1129 14:38:10.692137   95247 mcm_cloud_provider.go:165] Skipped node aws:///eu-west-1c/i-02e9dc684fa749102, it's either been removed or it's not managed by this controller
W1129 14:38:10.692157   95247 static_autoscaler.go:786] No node group for node aws:///eu-west-1c/i-02e9dc684fa749102, skipping
I1129 14:38:10.692240   95247 filter_out_schedulable.go:66] Filtering out schedulables
I1129 14:38:10.692264   95247 filter_out_schedulable.go:123] 0 pods marked as unschedulable can be scheduled.
I1129 14:38:10.692285   95247 filter_out_schedulable.go:86] No schedulable pods
I1129 14:38:10.692296   95247 filter_out_daemon_sets.go:40] Filtering out daemon set pods
I1129 14:38:10.692305   95247 filter_out_daemon_sets.go:49] Filtered out 0 daemon set pods, 0 unschedulable pods left
I1129 14:38:10.692338   95247 static_autoscaler.go:559] No unschedulable pods
I1129 14:38:10.692372   95247 static_autoscaler.go:582] Calculating unneeded nodes
I1129 14:38:10.692423   95247 pre_filtering_processor.go:67] Skipping ip-10-180-89-70.eu-west-1.compute.internal - node group min size reached (current: 1, min: 1)
I1129 14:38:10.692448   95247 pre_filtering_processor.go:67] Skipping ip-10-180-7-69.eu-west-1.compute.internal - node group min size reached (current: 0, min: 0)
I1129 14:38:10.692467   95247 mcm_cloud_provider.go:177] Skipped node aws:///eu-west-1c/i-0991ca1edca3e9474, it's not managed by this controller
I1129 14:38:10.692479   95247 pre_filtering_processor.go:57] Node ip-10-180-7-172.eu-west-1.compute.internal should not be processed by cluster autoscaler (no node group config)
I1129 14:38:10.692557   95247 static_autoscaler.go:626] Scale down status: lastScaleUpTime=2024-11-29 14:34:37.342074 +0530 IST m=+1195.040607251 lastScaleDownDeleteTime=2024-11-29 14:37:38.840165 +0530 IST m=+1376.519774668 lastScaleDownFailTime=2024-11-29 13:14:45.92434 +0530 IST m=-3596.406066582 scaleDownForbidden=false scaleDownInCooldown=true
I1129 14:38:17.272108   95247 reflector.go:871] pkg/mod/k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Watch close - *v1alpha1.Machine total 51 items received
I1129 14:38:21.166317   95247 static_autoscaler.go:306] Starting main loop
I1129 14:38:21.166603   95247 taints.go:442] Overriding status of node ip-10-180-7-172.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
I1129 14:38:21.166682   95247 taints.go:442] Overriding status of node ip-10-180-89-70.eu-west-1.compute.internal, which seems to have startup taint "testing.node.gardener.cloud/initial-node-blocked"
E1129 14:38:21.166801   95247 static_autoscaler.go:355] Failed to refresh cloud provider config: machine-controller-manager is offline. Cluster autoscaler operations would be suspended.
